{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh6aK4AtOJKl"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Группы тикеров\n",
        "groups = {\n",
        "    \"Equities\": [\"AAPL\", \"MSFT\", \"NVDA\", \"TSLA\", \"AMZN\", \"GOOG\", \"META\", \"JPM\", \"WMT\", \"NFLX\", \"BABA\", \"DIS\", \"PFE\", \"VZ\", \"KO\", \"INTC\", \"CSCO\", \"ADBE\", \"CMCSA\", \"T\"],\n",
        "    \"Commodities\": [\"CL=F\", \"GC=F\", \"SI=F\", \"HG=F\", \"ZS=F\"],\n",
        "    \"Equity Indices\": [\"^GSPC\", \"^DJI\", \"^IXIC\", \"^RUT\", \"^VIX\"],\n",
        "    \"Bond Indices\": [\"^TNX\", \"^IRX\", \"^TYX\"],\n",
        "    \"Currencies\": [\"EURUSD=X\", \"JPYUSD=X\", \"GBPUSD=X\", \"AUDUSD=X\", \"CADUSD=X\", \"CHFUSD=X\", \"CNYUSD=X\", \"SGDUSD=X\", \"HKDUSD=X\"]\n",
        "}\n",
        "\n",
        "base_dict = {}\n",
        "\n",
        "# Загрузка данных\n",
        "for group, tickers in groups.items():\n",
        "    for ticker in tqdm(tickers, desc=f\"Загрузка данных для группы {group}\"):\n",
        "        base_dict[ticker] = yf.download(ticker, start='1990-01-01', interval='1d')\n",
        "\n",
        "# Проверка структуры данных\n",
        "def check_data_structure(ticker, df):\n",
        "    print(f\"\\n--- Проверка структуры данных для {ticker} ---\")\n",
        "\n",
        "    # Проверка присутствия необходимых столбцов\n",
        "    required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            print(f\"Столбец {col} отсутствует в данных {ticker}\")\n",
        "        else:\n",
        "            print(f\"Столбец {col} присутствует в данных {ticker}\")\n",
        "\n",
        "    # Проверка частоты данных\n",
        "    print(f\"\\nЧастота данных для {ticker}:\\n\", pd.infer_freq(df.index))\n",
        "\n",
        "    # Проверка на пропуски данных\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(f\"\\nПропущенные значения в данных {ticker}:\\n\", missing_values)\n",
        "\n",
        "    # Проверка на нерегулярные даты\n",
        "    df['Date_Difference'] = df.index.to_series().diff().dt.days\n",
        "    irregular_dates = df[df['Date_Difference'] > 1]\n",
        "    if not irregular_dates.empty:\n",
        "        print(f\"\\nНайдены нерегулярные даты для {ticker}:\\n\", irregular_dates[['Date_Difference']])\n",
        "    else:\n",
        "        print(f\"\\nНерегулярных дат не найдено для {ticker}.\")\n",
        "\n",
        "# Основной цикл для проведения анализа структуры данных для каждой группы\n",
        "for group, tickers in groups.items():\n",
        "    print(f\"\\n=== Анализ структуры данных для группы {group} ===\")\n",
        "    for ticker in tickers:\n",
        "        df = base_dict[ticker]\n",
        "        check_data_structure(ticker, df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ресемплирование и вывод результатов\n",
        "def resample_data(df, freq, group_name, ticker_name):\n",
        "    df_resampled = df['Close'].resample(freq).mean()\n",
        "\n",
        "    # Интерполяция\n",
        "    df_resampled = df_resampled.interpolate(method='linear')\n",
        "\n",
        "    # Проверка на достаточное количество наблюдений для STL-декомпозиции\n",
        "    if len(df_resampled) < 24:\n",
        "        print(f\"Недостаточно данных для декомпозиции для {ticker_name} с частотой {freq}. Пропуск...\")\n",
        "        return\n",
        "\n",
        "    # Скользящее среднее\n",
        "    rolling_mean = df_resampled.rolling(window=50).mean()\n",
        "\n",
        "    # STL декомпозиция\n",
        "    result_stl = seasonal_decompose(df_resampled, model='additive', period=12)\n",
        "\n",
        "    # Z-score для выбросов\n",
        "    z_score = (df_resampled - df_resampled.mean()) / df_resampled.std()\n",
        "    outliers = z_score[np.abs(z_score) > 3]\n",
        "\n",
        "    # Визуализация\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    plt.subplot(4, 1, 1)\n",
        "    plt.plot(df_resampled, label=f'Resampled ({freq}) Close Prices')\n",
        "    plt.plot(rolling_mean, label=f'Rolling Mean', color='orange')\n",
        "    plt.title(f'{ticker_name} ({group_name}) - {freq} Resample and Rolling Mean')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(4, 1, 2)\n",
        "    plt.plot(result_stl.trend, label='Trend', color='green')\n",
        "    plt.title(f'{ticker_name} ({group_name}) - STL Trend Component')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(4, 1, 3)\n",
        "    plt.plot(result_stl.seasonal, label='Seasonality', color='purple')\n",
        "    plt.title(f'{ticker_name} ({group_name}) - STL Seasonal Component')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(4, 1, 4)\n",
        "    plt.scatter(outliers.index, outliers, color='red', label='Outliers (Z-score > 3)')\n",
        "    plt.title(f'{ticker_name} ({group_name}) - Detected Outliers')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Функция для проведения анализа с разными частотами ресемплирования\n",
        "def compare_resampling(df, group_name, ticker_name):\n",
        "    freqs = ['D', 'W', 'M', 'Q', 'A']  # День, Неделя, Месяц, Квартал, Год\n",
        "\n",
        "    for freq in freqs:\n",
        "        print(f\"Ресемплирование с частотой: {freq}\")\n",
        "        resample_data(df, freq, group_name, ticker_name)\n",
        "\n",
        "# Анализ данных для всех групп с разными частотами ресемплирования\n",
        "for group_name, tickers in groups.items():\n",
        "    for ticker in tickers:\n",
        "        df = base_dict[ticker]\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df = df.dropna()  # Удаление пропусков для чистоты эксперимента\n",
        "        compare_resampling(df, group_name, ticker)\n"
      ],
      "metadata": {
        "id": "AgfjA0J9uzwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "# Описательная статистика и агрегирование по группе\n",
        "def calculate_statistics_and_volatility(base_dict):\n",
        "    for group_name, tickers in groups.items():\n",
        "        print(f\"\\n=== Описательная статистика для группы {group_name} ===\")\n",
        "        group_stats = []\n",
        "\n",
        "        for ticker in tickers:\n",
        "            df = base_dict[ticker]\n",
        "\n",
        "            # Опис статистика\n",
        "            descriptive_stats = df['Close'].describe()\n",
        "            variance = df['Close'].var()\n",
        "            median = df['Close'].median()\n",
        "\n",
        "            print(f\"\\nСтатистические характеристики для {ticker}:\")\n",
        "            print(descriptive_stats)\n",
        "            print(f\"\\nДисперсия для {ticker}: {variance}\")\n",
        "            print(f\"Медиана для {ticker}: {median}\")\n",
        "\n",
        "            group_stats.append(df['Close'].describe())\n",
        "\n",
        "        # Агрегированная статистика для группп\n",
        "        aggregated_stats = pd.DataFrame(group_stats).mean()\n",
        "        print(f\"\\n=== Агрегированная описательная статистика для группы {group_name} ===\")\n",
        "        print(aggregated_stats)\n",
        "\n",
        "\n",
        "calculate_statistics_and_volatility(base_dict)\n",
        "\n",
        "# Функция для расчета волатильности на основе скользящего окна\n",
        "def calculate_moving_volatility(df, window=30):\n",
        "    \"\"\"\n",
        "    Функция для расчета волатильности на основе скользящего окна.\n",
        "    :param df: DataFrame с данными активов\n",
        "    :param window: Размер скользящего окна в днях\n",
        "    :return: Series с рассчитанной волатильностью\n",
        "    \"\"\"\n",
        "    returns = df['Close'].pct_change()  # Процентные изменения\n",
        "    volatility = returns.rolling(window=window).std() * np.sqrt(252)  # Годовая волатильность\n",
        "    return volatility\n",
        "\n",
        "# Функция для расчета волатильности для всей группы и построения графиков\n",
        "def calculate_all_group_volatility(window=30):\n",
        "    for group_name, tickers in groups.items():\n",
        "        group_volatilities = []\n",
        "        print(f\"\\n=== Волатильность для группы {group_name} ===\")\n",
        "\n",
        "        # Рассчитываем волатильность для каждого актива в группе\n",
        "        for ticker in tickers:\n",
        "            df = base_dict[ticker]\n",
        "            volatility = calculate_moving_volatility(df, window)\n",
        "\n",
        "            # Построение графика волатильности для каждого актива\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(df.index, volatility, label=f'{window}-Day Moving Volatility for {ticker}')\n",
        "            plt.title(f'Изменение волатильности за весь период для {ticker}')\n",
        "            plt.xlabel('Дата')\n",
        "            plt.ylabel('Волатильность')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "            group_volatilities.append(volatility)\n",
        "\n",
        "        # Агрегированная волатильность\n",
        "        group_volatility_avg = pd.concat(group_volatilities, axis=1).mean(axis=1)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(group_volatility_avg.index, group_volatility_avg, label=f'{window}-Day Avg Volatility for {group_name}')\n",
        "        plt.title(f'Агрегированная волатильность для группы {group_name}')\n",
        "        plt.xlabel('Дата')\n",
        "        plt.ylabel('Агрегированная волатильность')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "calculate_all_group_volatility(window=30)\n",
        "\n",
        "# Расчет корреляций и heatmap\n",
        "def calculate_group_correlations(base_dict):\n",
        "    group_close_prices = {}\n",
        "\n",
        "    for group, tickers in groups.items():\n",
        "        group_data = []\n",
        "        for ticker in tickers:\n",
        "            df = base_dict[ticker]\n",
        "            if 'Close' in df.columns:\n",
        "                group_data.append(df['Close'])\n",
        "        df_group = pd.concat(group_data, axis=1)\n",
        "        df_group.columns = tickers\n",
        "        group_close_prices[group] = df_group\n",
        "\n",
        "    # Все возможные пары групп\n",
        "    group_names = list(group_close_prices.keys())\n",
        "    group_pairs = [(group1, group2) for i, group1 in enumerate(group_names) for group2 in group_names[i+1:]]\n",
        "\n",
        "    # Цикл по парам групп для построения тепловых карт корреляций\n",
        "    for group1, group2 in group_pairs:\n",
        "        print(f\"\\nКорреляция между группами {group1} и {group2}:\")\n",
        "\n",
        "        # Данные для обеих групп\n",
        "        df_group1 = group_close_prices[group1].pct_change()\n",
        "        df_group2 = group_close_prices[group2].pct_change()\n",
        "\n",
        "        # Объединяем данные по обеим группам\n",
        "        combined_df = pd.concat([df_group1, df_group2], axis=1)\n",
        "\n",
        "        # Рассчитываем корреляцию между всеми активами из двух групп\n",
        "        correlation_matrix = combined_df.corr()\n",
        "\n",
        "        # Увеличиваем размер графика и убираем аннотации\n",
        "        plt.figure(figsize=(16, 12))\n",
        "        sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "        plt.title(f'Корреляция между {group1} и {group2}')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.show()\n",
        "\n",
        "calculate_group_correlations(base_dict)\n"
      ],
      "metadata": {
        "id": "D5TYKfN6QJ6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Функция для выполнения ADF теста (теста Дикки-Фуллера)\n",
        "def adf_test(df, title=\"\"):\n",
        "    print(f\"\\n{title}\")\n",
        "    result = adfuller(df.dropna())\n",
        "    print(f'ADF Statistic: {result[0]}')\n",
        "    print(f'p-value: {result[1]}')\n",
        "    print('Critical Values:')\n",
        "    for key, value in result[4].items():\n",
        "        print(f'   {key}: {value}')\n",
        "    if result[1] < 0.05:\n",
        "        print(\"Ряд стационарен (отклоняем нулевую гипотезу)\")\n",
        "    else:\n",
        "        print(\"Ряд нестационарен (не отклоняем нулевую гипотезу)\")\n",
        "\n",
        "# Построение ACF и PACF\n",
        "def plot_acf_pacf(df, title=\"\", lags=40):\n",
        "    # ACF (Автокорреляционная функция)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plot_acf(df.dropna(), lags=lags)\n",
        "    plt.title(f'ACF {title}')\n",
        "    plt.show()\n",
        "\n",
        "    # PACF (Частичная автокорреляционная функция)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plot_pacf(df.dropna(), lags=lags)\n",
        "    plt.title(f'PACF {title}')\n",
        "    plt.show()\n",
        "\n",
        "# Функция для выполнения тестов для каждого актива в группе\n",
        "def perform_individual_ts_tests(group_name, tickers, lags=40):\n",
        "    for ticker in tickers:\n",
        "        df = base_dict[ticker]\n",
        "        print(f\"\\nТестирование для актива {ticker} из группы {group_name}:\")\n",
        "\n",
        "        # Выполняем тест Дикки-Фуллера (ADF)\n",
        "        adf_test(df['Close'], title=f\"ADF для {ticker}\")\n",
        "\n",
        "        # Построение графиков ACF и PACF\n",
        "        plot_acf_pacf(df['Close'], title=f\"для {ticker}\", lags=lags)\n",
        "\n",
        "# Функция для вычисления среднего значения Close для группы активов\n",
        "def get_group_average(df_group):\n",
        "    return df_group.mean(axis=1)\n",
        "\n",
        "# Тесты на стационарность и автокорреляцию для группы активов\n",
        "def perform_group_ts_tests(group_name, tickers, lags=40):\n",
        "    # Собираем данные для группы\n",
        "    group_data = []\n",
        "    for ticker in tickers:\n",
        "        df = base_dict[ticker]\n",
        "        group_data.append(df['Close'])\n",
        "\n",
        "    # Рассчитываем среднее по группе\n",
        "    df_group = pd.concat(group_data, axis=1)\n",
        "    group_avg = get_group_average(df_group)\n",
        "\n",
        "    # Выполняем тесты для среднего по группе\n",
        "    print(f\"\\nТестирование для группы {group_name}:\")\n",
        "\n",
        "    # Выполняем тест Дикки-Фуллера (ADF) для среднего по группе\n",
        "    adf_test(group_avg, title=f\"ADF для группы {group_name}\")\n",
        "\n",
        "    # Построение ACF и PACF для среднего по группе\n",
        "    plot_acf_pacf(group_avg, title=f\"для группы {group_name}\", lags=lags)\n",
        "\n",
        "# Основная функция для выполнения тестов на стационарность и автокорреляцию как для индивидуальных активов, так и для групп\n",
        "def perform_ts_tests_for_all_groups():\n",
        "    for group_name, tickers in groups.items():\n",
        "        # Тесты для каждого актива в группе\n",
        "        perform_individual_ts_tests(group_name, tickers, lags=40)\n",
        "\n",
        "        # Тесты для группы в целом (агрегированные данные)\n",
        "        perform_group_ts_tests(group_name, tickers, lags=40)\n",
        "\n",
        "perform_ts_tests_for_all_groups()\n"
      ],
      "metadata": {
        "id": "4fM4VotmTJRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}