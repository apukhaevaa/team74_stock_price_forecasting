# Общий план работы над годовым проектом по теме: “Прогнозирование цен акций”


### 1. Разведочный анализ данных (Exploratory Data Analysis, EDA)
**Ответственные:** Все участники команды
**Сроки:** Октябрь 2024 – Ноябрь 2024

**Основные задачи:**

1.1 Список тикеров и групп активов
   - Определён перечень активов, включающий:
     - Акции (Equities): Тикеры крупнейших компаний, таких как Apple (AAPL), Microsoft (MSFT), Tesla (TSLA) и др.
     - Сырьевые товары (Commodities): Тикеры для нефти, золота, серебра и других сырьевых фьючерсов.
     - Индексы (Indices): Ключевые рыночные индексы (например, S&P 500, NASDAQ, и индекс волатильности VIX).
     - Облигации (Bond Indices): Доходности государственных облигаций США разного срока.
     - Валюты (Currencies): Валютные пары с долларом США.
   - Все активы разделены на группы для дальнейшего анализа.

1.2 Загрузка данных
   - Источник данных: Yahoo Finance.
   - Загружены исторические данные с 1 января 1990 года по текущий день с интервалом в один день.
   - Для каждого актива добавлены такие столбцы, как 'Date', 'Ticker', 'Company Name', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'.
   - Создан словарь с полными названиями компаний по тикерам для удобства работы с данными.

1.3 Первичный анализ структуры данных
   - Проверка наличия и структуры колонок: Убедились, что все активы имеют одинаковые колонки, необходимые для дальнейшего анализа.
   - Проверка типов данных: Убедились, что типы данных корректны и готовы к обработке.
   - Проверка частоты и пропусков: Выявлены возможные пропуски данных, которые будут учтены на следующих этапах.

1.4 Разделение на группы активов
   - Активы классифицированы по группам (Equities, Commodities, Indices, Bond Indices, Currencies) для облегчения анализа.

1.5 Очистка данных от выбросов
   - Используется статистика (например, 0.1% и 99.9% перцентили), чтобы определить экстремальные выбросы в данных.
   - Созданы словари для хранения как очищенных данных, так и выбросов.
   - Выведена информация о выбросах и очищенных данных для каждой группы активов.

1.6 Визуализация трендов
   - Построены графики трендов, средних значений и стандартного отклонения для каждого актива.
   - Проведена мультипликативная декомпозиция временного ряда для выявления трендов и сезонных составляющих.
   - Использована модель Prophet для прогнозирования данных, включая задание параметров модели и пользовательской сезонности. Построен прогноз на 365 дней вперед для каждого актива.

1.7 Заполнение пропусков
   - Создана функция для проверки наличия пропусков.
   - Пропуски заполнены методом линейной интерполяции, а оставшиеся пропуски (в начале или конце данных) заполнены методом ближайшего соседа.
   - Проверено отсутствие пропусков после заполнения.

1.8 Ресемплирование данных
   - Построены графики данных с разными интервалами ресемплирования для выявления сезонности и тенденций с разными временными интервалами.

1.9 Статистический анализ
   - Вычислены статистические характеристики для каждого актива.
   - Построена корреляционная тепловая карта для визуализации взаимосвязей между активами.

1.10 Тесты временных рядов на стационарность (ADF тест)
   - Проведен тест ADF (Augmented Dickey-Fuller) на стационарность для каждого актива.
   - Определено, стационарен ли временной ряд, что важно для последующего моделирования.

1.11 Анализ автокорреляции (ACF и PACF)
   - Проверка на автокорреляцию с использованием графиков ACF и PACF.
   - Анализ позволяет выявить сезонные паттерны и задержки, которые могут быть полезны для дальнейшего моделирования.

1.12 Обработка нестационарных рядов
   - Применено логарифмирование данных и тесты на стационарность для временных рядов.
   - Использованы скользящие метрики и графики автокорреляции для анализа после логарифмирования.
   - Проведено дифференцирование для достижения стационарности.

1.13 Поквартальный анализ
   - Проведен поквартальный анализ для выявления сезонных трендов и циклов.
   - Данные анализируются поквартально для каждой группы активов, что позволяет сравнить их влияние на общие рыночные тренды.

1.14 Загрузка макроэкономических данных
   - Использован API FRED для загрузки ключевых макроэкономических показателей (например, ВВП, безработица, CPI, процентные ставки).
   - Данные агрегированы поквартально для сравнения с поквартальными данными активов.

1.15 Анализ макроэкономических данных
   - Определены долгосрочные тренды и отклонения в макроэкономических показателях.
   - Для каждого показателя построены графики, на которых можно увидеть влияние мировых кризисов на экономику.

1.16 Тесты на стационарность для макроэкономических показателей
   - Проведены тесты ADF и KPSS для выявления стационарности макроэкономических показателей.
   - Определены ряды, требующие преобразования для дальнейшего анализа.

1.17 Преобразование данных для достижения стационарности
   - Применено разностное преобразование для достижения стационарности.
   - Получены скорректированные данные, которые позволяют анализировать изменения в динамике активов и макроэкономических показателей без учёта тренда и сезонности.

1.18 Финальная аналитика и построение корреляционных матриц:
   - Данные активов и макроэкономических показателей приведены к общему формату и нормализованы для анализа корреляции.
   - Построены корреляционные матрицы для выявления взаимосвязей между рыночными активами и макроэкономическими показателями, что позволяет делать выводы о влиянии макроэкономических факторов на рыночные активы.

1.19 Выполнен дополнительный пункт - анализ влияния. 

### 2. Разработка моделей машинного обучения (ML)
**Ответственные:** Все участники команды (разделение задач по моделям)
**Сроки:** Ноябрь 2024

**Основные задачи:**

2.1 Предобработка данных для ML:
- Применение методов финансового инжиниринга для создания новых признаков.
- Вычисление технических индикаторов, например таких как SMA, EMA, RSI, MACD и др.
- Создание временных лагов для использования в моделях временных рядов.

2.2 Разработка моделей:
- Классические модели временных рядов (SARIMAX), учет сезонности и остатков.
- Линейная регрессия, Random Forest, XGBoost и другие.
- Модель Prophet для долгосрочного прогнозирования (особенно для предсказания сезонных тенденций).
     
2.3 Метрики и подбор гиперпараметров:
- Оценка моделей по метрикам RMSE, MSE, MAE, и кросс-валидация для повышения устойчивости.
- Использование пайплайнов для автоматической проверки гиперпараметров через GridSearch, RandomSearch или другие методы с целью улучшения прогностической способности. 

2.4 Сравнение моделей и выводы:
- Сравнение ML-моделей между собой и выбор наиболее точной (точных) для дальнейшей работы. Создание единого пайплайна, который агрегирует результаты всех или наилучших моделей.

### 3. Разработка моделей глубокого обучения (DL)
**Ответственные:** Все участники команды (разделение задач по моделям)
**Сроки:** Январь 2025 – Март 2025

**Основные задачи:**
3.1 Модели глубокого обучения:
- Построение моделей LSTM и GRU для временных рядов.
- Использование архитектур с учетом многовариантности и сезонности данных.*
- Применение Attention-механизмов для улучшения точности.*

3.2 Оптимизация и настройка моделей:
- Оптимизация структуры сети и подбор гиперпараметров (размеры слоев, количество эпох, шаг обучения).
- Использование методов регуляризации для предотвращения переобучения.

3.3 Сравнение моделей:
- Сравнение моделей глубокого обучения с ML моделями по точности и эффективности.
- Пайплайн для создания ансамблей моделей для улучшения предсказательных способностей.

### 4. Создание сервиса для прогнозирования
**Ответственный:** Станислав Тюлягин 
**Сроки:** MVP к декабрю 2024, впоследствии доработка, наполнение и полная реализация к Апрелю – Маю 2025 года

**Основные задачи:** (идеальный вариант реализации, к которому будем стремится)

4.1 Архитектура сервиса
- Проектирование архитектуры сервиса на основе микросервисов с использованием фреймворка FastAPI (или аналогов).
- Подключение моделей для получения прогнозов.
- Проектирование базы данных для хранения исторических данных и результатов прогнозов.

4.2 Реализация API
- Разработка REST API для взаимодействия с моделями (ввод данных, получение прогнозов).
- Реализация эндпоинтов для работы с различными временными рамками (например, дневные, недельные прогнозы).
- Валидация и обработка входящих данных (от пользователей и источников данных).
- Подключение внешних источников для автоматического обновления данных (например, с помощью скриптов для парсинга API).**

4.3 Frontend (самый простой)
- Разработка простого пользовательского интерфейса для визуализации результатов прогнозов.
- Внедрение графиков для отображения исторических данных, текущих трендов и прогнозов.
- Интеграция функций для выбора акций, таймфреймов и отображения моделей с лучшей точностью прогноза.**

4.4 Развертывание и тестирование
- Настройка CI/CD процесса для автоматического тестирования и развертывания сервиса на облачных платформах (например, Yandex Cloud или DataSphere, или вдруг Вышка предоставит)
- Организация системы мониторинга производительности моделей (периодическая проверка точности прогнозов, обновление данных и моделей).**

4.5 Дополнительные задачи** (если останется время):
- Внедрение системы управления пользователями и доступа к сервису.
- Интеграция модели обработки новостных данных и сентимента для более точных прогнозов.
- Разработка мобильной версии интерфейса для использования на смартфонах.

**Этапы и сроки работы над веб-сервисом:**
+ Октябрь - Ноябрь 2024: Исследование архитектур для микросервисов, выбор фреймворка (FastAPI вероятней всего).
+ Ноябрь - Декабрь 2024: Разработка базового REST API (выход MVP).
+ Декабрь 2024: Тестирование API с простыми моделями (ML-модели).
+ Январь 2025: Внедрение DL-моделей в сервис и улучшение точности прогнозов.
+ Март 2025: Разработка интерфейса для пользователя (веб или мобильное приложение).
+ Май 2025: Финальное тестирование и развертывание сервиса на облачной платформе.


### 5. Финальная подготовка проекта и защита
**Ответственные:** Все участники команды
**Сроки:** Май-Июнь 2025

**Основные задачи:**
- Презентация финальных результатов (модели, сервис, визуализация).
- Оценка результатов работы моделей и точности прогнозов.
- Подготовка демонстрационного сценария работы сервиса.
- Финальное тестирование и улучшение сервиса.
- Написание и публикация статьи по проделанной работе / о полученных результатах
