{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEAM 74: STOCK PRICE FORECASTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from scipy import stats\n",
    "from fredapi import Fred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# Список тикеров (акции, товары, индексы, облигации, валюты)\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Список тикеров (акции, товары, индексы, облигации, валюты)\n",
    "most_traded_tickers = [\n",
    "    # Акции\n",
    "    \"AAPL\", \"MSFT\", \"NVDA\", \"TSLA\", \"AMZN\", \"GOOG\", \"META\", \"JPM\", \"WMT\", \"NFLX\",\n",
    "    \"BABA\", \"DIS\", \"PFE\", \"VZ\", \"KO\", \"INTC\", \"CSCO\", \"ADBE\", \"CMCSA\", \"T\",\n",
    "\n",
    "    # Сырьевые товары\n",
    "    \"CL=F\", \"GC=F\", \"SI=F\", \"HG=F\", \"ZS=F\",\n",
    "\n",
    "    # Индексы\n",
    "    \"^GSPC\", \"^DJI\", \"^IXIC\", \"^RUT\", \"^VIX\",\n",
    "\n",
    "    # Облигации\n",
    "    \"^TNX\", \"^IRX\", \"^TYX\",\n",
    "\n",
    "    # Валюты\n",
    "    \"EURUSD=X\", \"JPYUSD=X\", \"GBPUSD=X\", \"AUDUSD=X\", \"CADUSD=X\",\n",
    "    \"CHFUSD=X\", \"CNYUSD=X\", \"SGDUSD=X\", \"HKDUSD=X\"\n",
    "]\n",
    "\n",
    "# Группы активов для анализа\n",
    "asset_classes = {\n",
    "    \"Equities\": [\n",
    "        \"AAPL\", \"MSFT\", \"NVDA\", \"TSLA\", \"AMZN\", \"GOOG\", \"META\", \"JPM\", \"WMT\", \"NFLX\",\n",
    "        \"BABA\", \"DIS\", \"PFE\", \"VZ\", \"KO\", \"INTC\", \"CSCO\", \"ADBE\", \"CMCSA\", \"T\"\n",
    "    ],\n",
    "    \"Commodities\": [\"CL=F\", \"GC=F\", \"SI=F\", \"HG=F\", \"ZS=F\"],\n",
    "    \"Indices\": [\"^GSPC\", \"^DJI\", \"^IXIC\", \"^RUT\", \"^VIX\"],\n",
    "    \"Bond Indices\": [\"^TNX\", \"^IRX\", \"^TYX\"],\n",
    "    \"Currencies\": [\n",
    "        \"EURUSD=X\", \"JPYUSD=X\", \"GBPUSD=X\", \"AUDUSD=X\", \"CADUSD=X\",\n",
    "        \"CHFUSD=X\", \"CNYUSD=X\", \"SGDUSD=X\", \"HKDUSD=X\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 0. Загрузка данных\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dict = {}\n",
    "data_list = []\n",
    "\n",
    "for ticker in tqdm(most_traded_tickers):\n",
    "    # Загрузка данных и названия компании\n",
    "    data = yf.download(ticker, start='1990-01-01', interval='1d')\n",
    "    info = yf.Ticker(ticker).info\n",
    "    company_name = info.get(\"shortName\", ticker)  # Используем тикер, если название недоступно\n",
    "\n",
    "    # Добавление названия компании и тикера в данные\n",
    "    data['Ticker'] = ticker\n",
    "    data['Company Name'] = company_name\n",
    "    data_list.append(data)\n",
    "\n",
    "# Объединение данных в один DataFrame\n",
    "full_data = pd.concat(data_list)\n",
    "full_data.reset_index(inplace=True)  # Сброс индекса для красоты\n",
    "\n",
    "# Сохранение в красивую таблицу\n",
    "full_data = full_data[['Date', 'Ticker', 'Company Name', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "full_data.to_csv(\"data_with_company_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 1. Изучение структуры данных\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Словарь для хранения полных названий компаний по тикерам\n",
    "full_names = {\n",
    "    \"AAPL\": \"Apple Inc.\", \"MSFT\": \"Microsoft Corporation\", \"NVDA\": \"NVIDIA Corporation\", \"TSLA\": \"Tesla Inc.\",\n",
    "    \"AMZN\": \"Amazon.com Inc.\", \"GOOG\": \"Alphabet Inc.\", \"META\": \"Meta Platforms, Inc.\", \"JPM\": \"JPMorgan Chase & Co.\",\n",
    "    \"WMT\": \"Walmart Inc.\", \"NFLX\": \"Netflix, Inc.\", \"BABA\": \"Alibaba Group Holding Limited\",\n",
    "    \"DIS\": \"The Walt Disney Company\", \"PFE\": \"Pfizer Inc.\", \"VZ\": \"Verizon Communications Inc.\",\n",
    "    \"KO\": \"The Coca-Cola Company\", \"INTC\": \"Intel Corporation\", \"CSCO\": \"Cisco Systems, Inc.\",\n",
    "    \"ADBE\": \"Adobe Inc.\", \"CMCSA\": \"Comcast Corporation\", \"T\": \"AT&T Inc.\",\n",
    "    \"CL=F\": \"Crude Oil Futures\", \"GC=F\": \"Gold Futures\", \"SI=F\": \"Silver Futures\", \n",
    "    \"HG=F\": \"Copper Futures\", \"ZS=F\": \"Soybean Futures\",\n",
    "    \"^GSPC\": \"S&P 500\", \"^DJI\": \"Dow Jones Industrial Average\", \"^IXIC\": \"NASDAQ Composite\", \n",
    "    \"^RUT\": \"Russell 2000\", \"^VIX\": \"Volatility Index\",\n",
    "    \"^TNX\": \"10-Year Treasury Yield\", \"^IRX\": \"13-Week Treasury Bill Yield\", \"^TYX\": \"30-Year Treasury Yield\",\n",
    "    \"EURUSD=X\": \"Euro/US Dollar\", \"JPYUSD=X\": \"Japanese Yen/US Dollar\", \"GBPUSD=X\": \"British Pound/US Dollar\",\n",
    "    \"AUDUSD=X\": \"Australian Dollar/US Dollar\", \"CADUSD=X\": \"Canadian Dollar/US Dollar\",\n",
    "    \"CHFUSD=X\": \"Swiss Franc/US Dollar\", \"CNYUSD=X\": \"Chinese Yuan/US Dollar\", \n",
    "    \"SGDUSD=X\": \"Singapore Dollar/US Dollar\", \"HKDUSD=X\": \"Hong Kong Dollar/US Dollar\"\n",
    "}\n",
    "\n",
    "# Загружаем данные для каждого тикера и добавляем их в словарь\n",
    "base_dict = {}\n",
    "for ticker in tqdm(full_names.keys()):\n",
    "    base_dict[ticker] = yf.download(ticker, start='1990-01-01', interval='1d')\n",
    "\n",
    "# ============================================\n",
    "# A) Проверка на наличие необходимых колонок и структура данных\n",
    "# ============================================\n",
    "\n",
    "def check_columns_and_structure(data, ticker):\n",
    "    # Вывод первых 5 строк с названием компании и тикером\n",
    "    table = data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].head(5)\n",
    "    table[\"Ticker\"] = ticker\n",
    "    table[\"Full Name\"] = full_names.get(ticker, \"Unknown\")\n",
    "    print(tabulate(table, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "    return table\n",
    "\n",
    "# Проверка колонок и структуры данных для всех активов\n",
    "column_structure_data = {ticker: check_columns_and_structure(data, ticker) for ticker, data in base_dict.items()}\n",
    "\n",
    "# ============================================\n",
    "# B) Проверка структуры типов данных\n",
    "# ============================================\n",
    "\n",
    "def check_data_types(data, ticker):\n",
    "    # Структура типов данных, первые 5 строк\n",
    "    types_table = pd.DataFrame(data.dtypes, columns=[\"Data Type\"]).reset_index()\n",
    "    types_table[\"Ticker\"] = ticker\n",
    "    types_table[\"Full Name\"] = full_names.get(ticker, \"Unknown\")\n",
    "    print(tabulate(types_table, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "    return types_table\n",
    "\n",
    "# Проверка структуры типов данных для всех активов\n",
    "data_types_data = {ticker: check_data_types(data, ticker) for ticker, data in base_dict.items()}\n",
    "\n",
    "# ============================================\n",
    "# C) Проверка частоты и пропусков\n",
    "# ============================================\n",
    "\n",
    "def check_frequency_and_missing(data, ticker):\n",
    "    freq = pd.infer_freq(data.index)\n",
    "    missing_data = data.isna().sum().reset_index()\n",
    "    missing_data.columns = [\"Column\", \"Missing Values\"]\n",
    "    missing_data[\"Ticker\"] = ticker\n",
    "    missing_data[\"Full Name\"] = full_names.get(ticker, \"Unknown\")\n",
    "    print(f\"\\nЧастота данных для {ticker} ({full_names.get(ticker)}): {freq}\")\n",
    "    print(tabulate(missing_data, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "    return freq, missing_data\n",
    "\n",
    "# Проверка частоты и пропусков для всех активов\n",
    "frequency_missing_data = {ticker: check_frequency_and_missing(data, ticker) for ticker, data in base_dict.items()}\n",
    "\n",
    "# ============================================\n",
    "# D) Разделение на группы активов и корректное определение\n",
    "# ============================================\n",
    "\n",
    "asset_classes = {\n",
    "    \"Equities\": [\"AAPL\", \"MSFT\", \"NVDA\", \"TSLA\", \"AMZN\", \"GOOG\", \"META\", \"JPM\", \"WMT\", \"NFLX\",\n",
    "                 \"BABA\", \"DIS\", \"PFE\", \"VZ\", \"KO\", \"INTC\", \"CSCO\", \"ADBE\", \"CMCSA\", \"T\"],\n",
    "    \"Commodities\": [\"CL=F\", \"GC=F\", \"SI=F\", \"HG=F\", \"ZS=F\"],\n",
    "    \"Indices\": [\"^GSPC\", \"^DJI\", \"^IXIC\", \"^RUT\", \"^VIX\"],\n",
    "    \"Bond Indices\": [\"^TNX\", \"^IRX\", \"^TYX\"],\n",
    "    \"Currencies\": [\"EURUSD=X\", \"JPYUSD=X\", \"GBPUSD=X\", \"AUDUSD=X\", \"CADUSD=X\",\n",
    "                   \"CHFUSD=X\", \"CNYUSD=X\", \"SGDUSD=X\", \"HKDUSD=X\"]\n",
    "}\n",
    "\n",
    "def check_asset_groups():\n",
    "    group_data = []\n",
    "    for group, tickers in asset_classes.items():\n",
    "        for ticker in tickers:\n",
    "            group_data.append({\n",
    "                \"Asset Group\": group,\n",
    "                \"Ticker\": ticker,\n",
    "                \"Full Name\": full_names.get(ticker, \"Unknown\")\n",
    "            })\n",
    "    \n",
    "    group_df = pd.DataFrame(group_data)\n",
    "    print(tabulate(group_df, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "    return group_df\n",
    "\n",
    "# Разделение на группы активов\n",
    "asset_groups_data = check_asset_groups()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 2. Очистка выбросов по всем    активам\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Описательная статистика по каждому активу в словаре base_dict\n",
    "\n",
    "for ticker, df in base_dict.items():\n",
    "\n",
    "    print(f\"\\nОписательная статистика для {ticker}:\")\n",
    "\n",
    "    display(df.describe())\n",
    "\n",
    "# Функция для удаления экстремальных выбросов по строгим критериям (например, 0.1% и 99.9% перцентили)\n",
    "\n",
    "def remove_extreme_outliers(data, column, ticker):\n",
    "\n",
    "    lower_threshold = data[column].quantile(0.001)  # 0.1-й перцентиль\n",
    "\n",
    "    upper_threshold = data[column].quantile(0.999)  # 99.9-й перцентиль\n",
    "\n",
    "\n",
    "\n",
    "    # Отбираем выбросы и очищенные данные\n",
    "\n",
    "    outliers = data[(data[column] < lower_threshold) | (data[column] > upper_threshold)]\n",
    "\n",
    "    cleaned_data = data[(data[column] >= lower_threshold) & (data[column] <= upper_threshold)]\n",
    "\n",
    "    \n",
    "\n",
    "    return cleaned_data, outliers\n",
    "\n",
    "\n",
    "\n",
    "# Словари для хранения очищенных данных и выбросов\n",
    "\n",
    "cleaned_data_dict = {}\n",
    "\n",
    "outliers_data_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# Очистка выбросов для всех активов в словаре\n",
    "\n",
    "for ticker, df in base_dict.items():\n",
    "\n",
    "    if isinstance(df, pd.DataFrame) and 'Adj Close' in df.columns:\n",
    "\n",
    "        cleaned_data, outliers = remove_extreme_outliers(df, 'Adj Close', ticker)\n",
    "\n",
    "        \n",
    "\n",
    "        cleaned_data_dict[ticker] = cleaned_data\n",
    "\n",
    "        outliers_data_dict[ticker] = outliers\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f\"Пропуск {ticker}: неверный формат данных или отсутствует столбец 'Adj Close'.\")\n",
    "\n",
    "\n",
    "\n",
    "# Функция для форматирования таблицы с первыми 10 значениями\n",
    "\n",
    "def display_summary_table(data, title, info):\n",
    "\n",
    "    summary_table = data.head(10)  # только первые 10 строк\n",
    "\n",
    "    styled_table = summary_table.style.set_caption(f\"{title} ({info})\").set_properties(**{\n",
    "\n",
    "        'border': '1px solid black',\n",
    "\n",
    "        'padding': '8px'\n",
    "\n",
    "    }).set_table_styles([\n",
    "\n",
    "        dict(selector=\"thead\", props=[(\"background-color\", \"#CCCCCC\"), (\"color\", \"black\")]),\n",
    "\n",
    "        dict(selector=\"tbody tr:nth-child(even)\", props=[(\"background-color\", \"#F2F2F2\")]),\n",
    "\n",
    "        dict(selector=\"tbody tr:nth-child(odd)\", props=[(\"background-color\", \"white\")])\n",
    "\n",
    "    ])\n",
    "\n",
    "    display(styled_table)\n",
    "\n",
    "\n",
    "\n",
    "# Вывод информации по каждому активу\n",
    "\n",
    "for ticker, outliers in outliers_data_dict.items():\n",
    "\n",
    "    num_outliers = len(outliers)\n",
    "\n",
    "    num_total = len(base_dict[ticker]) if ticker in base_dict else 0\n",
    "\n",
    "    num_cleaned = num_total - num_outliers\n",
    "\n",
    "    \n",
    "\n",
    "    # Отображение информации о выбросах\n",
    "\n",
    "    if not outliers.empty:\n",
    "\n",
    "        display_summary_table(outliers, f\"Выбросы для {ticker}\", f\"Найдено выбросов: {num_outliers}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Отображение информации об очищенных данных\n",
    "\n",
    "    display_summary_table(cleaned_data_dict[ticker], f\"Очищенные данные для {ticker}\", f\"Осталось после удаления: {num_cleaned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 3. Визуализация трендов\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Функция для визуализации трендов, средних и стандартного отклонения\n",
    "\n",
    "def visualize_trends_and_stats(data, ticker, title, start_date, end_date):\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.plot(data.index, data['Adj Close'], label='Price', color='blue')\n",
    "\n",
    "    \n",
    "\n",
    "    rolling_mean = data['Adj Close'].rolling(window=365).mean()\n",
    "\n",
    "    rolling_std = data['Adj Close'].rolling(window=365).std()\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(data.index, rolling_mean, label='365-Day Rolling Mean', color='green')\n",
    "\n",
    "    plt.plot(data.index, rolling_std, label='365-Day Rolling Std', color='red')\n",
    "\n",
    "    \n",
    "\n",
    "    plt.title(f'{title} ({start_date.date()} - {end_date.date()})')\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "\n",
    "    plt.ylabel('Adjusted Closing Price')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Функция для мультипликативной декомпозиции временного ряда\n",
    "\n",
    "def plot_multiplicative_decomposition(data, ticker, title):\n",
    "\n",
    "    result = seasonal_decompose(data['Adj Close'], model='multiplicative', period=365)\n",
    "\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    \n",
    "\n",
    "    result.observed.plot(ax=ax1, color='blue')\n",
    "\n",
    "    ax1.set_ylabel('Observed')\n",
    "\n",
    "    result.trend.plot(ax=ax2, color='blue')\n",
    "\n",
    "    ax2.set_ylabel('Trend')\n",
    "\n",
    "    result.seasonal.plot(ax=ax3, color='blue')\n",
    "\n",
    "    ax3.set_ylabel('Seasonal')\n",
    "\n",
    "    result.resid.plot(ax=ax4, color='blue')\n",
    "\n",
    "    ax4.set_ylabel('Residual')\n",
    "\n",
    "    \n",
    "\n",
    "    plt.suptitle(f'Multiplicative Decomposition for {title}', y=1.02)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Визуализация данных для каждого актива\n",
    "\n",
    "for ticker, data in cleaned_data_dict.items():\n",
    "\n",
    "    start_date = data.index.min()\n",
    "\n",
    "    end_date = data.index.max()\n",
    "\n",
    "    title = f\"{full_names.get(ticker, ticker)}\"\n",
    "\n",
    "    \n",
    "\n",
    "    # Визуализация трендов, средних и стандартного отклонения\n",
    "\n",
    "    visualize_trends_and_stats(data, ticker, title, start_date, end_date)\n",
    "\n",
    "    \n",
    "\n",
    "    # Мультипликативная декомпозиция\n",
    "\n",
    "    plot_multiplicative_decomposition(data, ticker, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Задаем параметры модели Prophet и добавляем пользовательскую сезонность\n",
    "\n",
    "def create_and_train_prophet_model(data):\n",
    "\n",
    "    model = Prophet(seasonality_mode='additive', yearly_seasonality=True)\n",
    "\n",
    "    model.add_seasonality(name='custom_yearly', period=30.5, fourier_order=5)\n",
    "\n",
    "    model.fit(data)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Функция для построения прогноза и визуализации\n",
    "\n",
    "def plot_prophet_forecast(data, ticker, title, forecast_period=365):\n",
    "\n",
    "    # Разделяем данные на обучающую и тестовую выборки\n",
    "\n",
    "    train_data = data[:-forecast_period]\n",
    "\n",
    "    \n",
    "\n",
    "    # Подготовка данных для Prophet\n",
    "\n",
    "    prophet_data = train_data.reset_index().rename(columns={'Date': 'ds', 'Adj Close': 'y'})\n",
    "\n",
    "    \n",
    "\n",
    "    # Создание и обучение модели\n",
    "\n",
    "    model = create_and_train_prophet_model(prophet_data)\n",
    "\n",
    "    \n",
    "\n",
    "    # Создание датафрейма для прогноза на 365 дней вперед\n",
    "\n",
    "    future = model.make_future_dataframe(periods=forecast_period)\n",
    "\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    \n",
    "\n",
    "    # Визуализация прогноза\n",
    "\n",
    "    fig = model.plot(forecast)\n",
    "\n",
    "    plt.title(f'{title} - Prophet Forecast')\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "\n",
    "    plt.ylabel('Price')\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Визуализация прогноза для каждого актива\n",
    "\n",
    "for ticker, data in cleaned_data_dict.items():\n",
    "\n",
    "    title = f\"{full_names.get(ticker, ticker)}\"\n",
    "\n",
    "    plot_prophet_forecast(data, ticker, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 4. Групповая визуализация для каждой группы активов\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Функция для групповой визуализации\n",
    "\n",
    "def plot_grouped_assets(data_dict, groups, cleaned_data_dict):\n",
    "\n",
    "    for group_name, tickers in groups.items():\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        start_date, end_date = None, None  # Переменные для хранения периода\n",
    "\n",
    "\n",
    "\n",
    "        for ticker in tickers:\n",
    "\n",
    "            data = cleaned_data_dict.get(ticker)\n",
    "\n",
    "            if data is not None:\n",
    "\n",
    "                plt.plot(data.index, data['Adj Close'], label=f\"{full_names.get(ticker, ticker)} ({ticker})\")\n",
    "\n",
    "                \n",
    "\n",
    "                # Обновляем значения начала и конца периода\n",
    "\n",
    "                if start_date is None or data.index.min() < start_date:\n",
    "\n",
    "                    start_date = data.index.min()\n",
    "\n",
    "                if end_date is None or data.index.max() > end_date:\n",
    "\n",
    "                    end_date = data.index.max()\n",
    "\n",
    "\n",
    "\n",
    "        plt.title(f\"{group_name} (Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')})\")\n",
    "\n",
    "        plt.xlabel(\"Date\")\n",
    "\n",
    "        plt.ylabel(\"Adjusted Closing Price\")\n",
    "\n",
    "        plt.legend(loc=\"best\")\n",
    "\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Вызов функции для групповой визуализации\n",
    "\n",
    "plot_grouped_assets(base_dict, asset_classes, cleaned_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 5. Проверка и подсчет пропусков в данных\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "# Функция для проверки пропусков в данных\n",
    "\n",
    "def check_missing_data(cleaned_data_dict):\n",
    "\n",
    "    # Создаем список для сбора информации о пропусках\n",
    "\n",
    "    missing_data_summary = []\n",
    "\n",
    "\n",
    "\n",
    "    # Проходим по каждому активу в очищенных данных\n",
    "\n",
    "    for ticker, data in cleaned_data_dict.items():\n",
    "\n",
    "        if data is not None:\n",
    "\n",
    "            missing_count = data.isnull().sum().sum()  # Количество пропусков\n",
    "\n",
    "            total_count = data.shape[0] * data.shape[1]  # Общее количество элементов\n",
    "\n",
    "            missing_percentage = (missing_count / total_count) * 100  # Процент пропусков\n",
    "\n",
    "            \n",
    "\n",
    "            # Добавляем данные в таблицу\n",
    "\n",
    "            missing_data_summary.append({\n",
    "\n",
    "                'Ticker': ticker,\n",
    "\n",
    "                'Full Name': full_names.get(ticker, ticker),\n",
    "\n",
    "                'Total Missing Values': missing_count,\n",
    "\n",
    "                'Missing Percentage (%)': round(missing_percentage, 2)\n",
    "\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "    # Создаем DataFrame для отображения результатов\n",
    "\n",
    "    missing_data_df = pd.DataFrame(missing_data_summary)\n",
    "\n",
    "    display(missing_data_df)\n",
    "\n",
    "\n",
    "\n",
    "# Вызов функции для проверки пропусков в очищенных данных\n",
    "\n",
    "check_missing_data(cleaned_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция для заполнения пропусков линейной интерполяцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "# Функция для заполнения пропусков линейной интерполяцией\n",
    "\n",
    "def fill_missing_data(cleaned_data_dict):\n",
    "\n",
    "    filled_data_dict = {}\n",
    "\n",
    "    for ticker, data in cleaned_data_dict.items():\n",
    "\n",
    "        if data is not None:\n",
    "\n",
    "            # Заполняем пропуски методом линейной интерполяции\n",
    "\n",
    "            filled_data = data.interpolate(method='linear')\n",
    "\n",
    "            # Заполнение оставшихся (если есть в начале или конце) методом ближайшего соседа\n",
    "\n",
    "            filled_data = filled_data.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "            filled_data_dict[ticker] = filled_data\n",
    "\n",
    "    return filled_data_dict\n",
    "\n",
    "\n",
    "\n",
    "# Заполнение пропусков в данных\n",
    "\n",
    "filled_data_dict = fill_missing_data(cleaned_data_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Функция для проверки и отображения оставшихся пропусков по каждому активу\n",
    "\n",
    "def check_missing_data(data_dict, full_names):\n",
    "\n",
    "    missing_data_summary = []\n",
    "\n",
    "    for ticker, data in data_dict.items():\n",
    "\n",
    "        missing_count = data.isnull().sum().sum()  # Суммируем все пропуски по столбцам\n",
    "\n",
    "        company_name = full_names.get(ticker, \"Unknown\")  # Получаем полное название компании\n",
    "\n",
    "        missing_data_summary.append({'Ticker': ticker, 'Company Name': company_name, 'Missing Values': missing_count})\n",
    "\n",
    "\n",
    "\n",
    "    # Создаем DataFrame для наглядного отображения результатов\n",
    "\n",
    "    missing_data_df = pd.DataFrame(missing_data_summary)\n",
    "\n",
    "    display(missing_data_df)\n",
    "\n",
    "\n",
    "\n",
    "# Проверка на наличие пропусков после заполнения\n",
    "\n",
    "check_missing_data(filled_data_dict, full_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 6. Первичная визуализация: ресемплирование\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Параметры для отображения графиков\n",
    "\n",
    "plt.style.use('ggplot')  # Используем стиль ggplot для визуализации\n",
    "\n",
    "\n",
    "\n",
    "# Функция для визуализации данных с разными интервалами ресемплирования для каждого актива\n",
    "\n",
    "def plot_resampled_data_individual(filled_data_dict, full_names):\n",
    "\n",
    "    resample_dict = {\n",
    "\n",
    "        'D': 'Дни',         # Дни\n",
    "\n",
    "        'W': 'Недели',      # Недели\n",
    "\n",
    "        'M': 'Месяцы',      # Месяцы\n",
    "\n",
    "        'Q': 'Кварталы',    # Кварталы\n",
    "\n",
    "        '6M': '6 Месяцев',  # 6 месяцев\n",
    "\n",
    "        'A': 'Годы'         # Годы\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    # Создание графиков для каждого актива\n",
    "\n",
    "    for ticker, data in filled_data_dict.items():\n",
    "\n",
    "        company_name = full_names.get(ticker, 'Unknown')\n",
    "\n",
    "        start_date = data.index.min().strftime('%Y-%m-%d')\n",
    "\n",
    "        end_date = data.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
    "\n",
    "        fig.suptitle(f'Ресемплированные данные для {company_name} ({ticker})\\nПериод: {start_date} - {end_date}', fontsize=16)\n",
    "\n",
    "        plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "\n",
    "\n",
    "        for i, (freq, label) in enumerate(resample_dict.items()):\n",
    "\n",
    "            resampled_data = data['Adj Close'].resample(freq).mean()  # Ресемплирование с расчетом среднего значения\n",
    "\n",
    "\n",
    "\n",
    "            ax = axes[i // 3, i % 3]\n",
    "\n",
    "            ax.plot(resampled_data.index, resampled_data, label=f'{company_name} ({ticker}) - {label}')\n",
    "\n",
    "            ax.set_title(f'{label}')\n",
    "\n",
    "            ax.set_xlabel('Дата')\n",
    "\n",
    "            ax.set_ylabel('Цена')\n",
    "\n",
    "            ax.legend()\n",
    "\n",
    "            ax.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Вызов функции для отображения графиков для каждого актива\n",
    "\n",
    "plot_resampled_data_individual(filled_data_dict, full_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 7. Статистические характеристики\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Функция для расчета статистических характеристик\n",
    "\n",
    "def calculate_statistics(data, interval_name, interval_label):\n",
    "\n",
    "    stats_dict = {\n",
    "\n",
    "        'Тикер': [],\n",
    "\n",
    "        'Название': [],\n",
    "\n",
    "        'Интервал': [],\n",
    "\n",
    "        'Медиана (абс.)': [],\n",
    "\n",
    "        'Дисперсия (абс.)': [],\n",
    "\n",
    "        'Стандартное отклонение (абс.)': [],\n",
    "\n",
    "        'Волатильность (%)': []\n",
    "\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    for ticker, df in data.items():\n",
    "\n",
    "        company_name = full_names.get(ticker, 'Unknown')\n",
    "\n",
    "        resampled_data = df['Adj Close'].resample(interval_name).mean()\n",
    "\n",
    "        \n",
    "\n",
    "        # Заполнение пропусков, чтобы избежать предупреждений\n",
    "\n",
    "        resampled_data = resampled_data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        \n",
    "\n",
    "        stats_dict['Тикер'].append(ticker)\n",
    "\n",
    "        stats_dict['Название'].append(company_name)\n",
    "\n",
    "        stats_dict['Интервал'].append(interval_label)\n",
    "\n",
    "        stats_dict['Медиана (абс.)'].append(resampled_data.median())\n",
    "\n",
    "        stats_dict['Дисперсия (абс.)'].append(resampled_data.var())\n",
    "\n",
    "        stats_dict['Стандартное отклонение (абс.)'].append(resampled_data.std())\n",
    "\n",
    "        stats_dict['Волатильность (%)'].append(resampled_data.pct_change().std() * np.sqrt(len(resampled_data)) * 100)\n",
    "\n",
    "    \n",
    "\n",
    "    return pd.DataFrame(stats_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Функция для создания и отображения тепловой карты корреляций\n",
    "\n",
    "def plot_correlation_heatmap(data, interval_name, interval_label):\n",
    "\n",
    "    resampled_data = {ticker: df['Adj Close'].resample(interval_name).mean().fillna(method='ffill').fillna(method='bfill') for ticker, df in data.items()}\n",
    "\n",
    "    correlation_df = pd.DataFrame(resampled_data).corr()\n",
    "\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    sns.heatmap(correlation_df, annot=False, cmap=\"coolwarm\", cbar=True, xticklabels=correlation_df.columns, yticklabels=correlation_df.index)\n",
    "\n",
    "    plt.title(f'Корреляционная матрица между активами - {interval_label}')\n",
    "\n",
    "    \n",
    "\n",
    "    # Добавляем легенду с полными названиями\n",
    "\n",
    "    plt.figtext(1.15, 0.5, \"\\n\".join([f\"{ticker} - {full_names[ticker]}\" for ticker in correlation_df.columns]), horizontalalignment='left', verticalalignment='center', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Словарь для интервалов и меток\n",
    "\n",
    "intervals = {\n",
    "\n",
    "    'D': 'День',\n",
    "\n",
    "    'W': 'Неделя',\n",
    "\n",
    "    'M': 'Месяц',\n",
    "\n",
    "    'Q': 'Квартал',\n",
    "\n",
    "    '6M': '6 Месяцев',\n",
    "\n",
    "    'A': 'Год'\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Проходим по каждому временному интервалу, рассчитываем статистику и строим корреляционные матрицы\n",
    "\n",
    "for interval, label in intervals.items():\n",
    "\n",
    "    # Рассчёт статистических характеристик\n",
    "\n",
    "    stats_df = calculate_statistics(filled_data_dict, interval, label)\n",
    "\n",
    "    print(f\"Статистические характеристики - {label}\")\n",
    "\n",
    "    display(stats_df)\n",
    "\n",
    "\n",
    "\n",
    "    # Построение корреляционной тепловой карты\n",
    "\n",
    "    plot_correlation_heatmap(filled_data_dict, interval, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 8. Тесты временных рядов (ADF), ADF tests\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "\n",
    "# Функция для выполнения теста ADF по каждому активу и сбор результатов в таблицу\n",
    "\n",
    "def perform_adf_test(data):\n",
    "\n",
    "    adf_results = {\n",
    "\n",
    "        'Тикер': [],\n",
    "\n",
    "        'Название': [],\n",
    "\n",
    "        'Test Statistic': [],\n",
    "\n",
    "        'p-value': [],\n",
    "\n",
    "        'Critical Value (1%)': [],\n",
    "\n",
    "        'Critical Value (5%)': [],\n",
    "\n",
    "        'Critical Value (10%)': [],\n",
    "\n",
    "        'Стационарность': []\n",
    "\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    for ticker, df in data.items():\n",
    "\n",
    "        company_name = full_names.get(ticker, 'Unknown')\n",
    "\n",
    "        \n",
    "\n",
    "        # Выполнение теста ADF\n",
    "\n",
    "        adf_test = adfuller(df['Adj Close'].dropna())\n",
    "\n",
    "        test_statistic = adf_test[0]\n",
    "\n",
    "        p_value = adf_test[1]\n",
    "\n",
    "        critical_values = adf_test[4]\n",
    "\n",
    "        \n",
    "\n",
    "        # Определение стационарности\n",
    "\n",
    "        if p_value < 0.05:\n",
    "\n",
    "            stationarity = \"Стационарен\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            stationarity = \"Нестационарен\"\n",
    "\n",
    "        \n",
    "\n",
    "        # Добавление данных в таблицу результатов\n",
    "\n",
    "        adf_results['Тикер'].append(ticker)\n",
    "\n",
    "        adf_results['Название'].append(company_name)\n",
    "\n",
    "        adf_results['Test Statistic'].append(test_statistic)\n",
    "\n",
    "        adf_results['p-value'].append(p_value)\n",
    "\n",
    "        adf_results['Critical Value (1%)'].append(critical_values['1%'])\n",
    "\n",
    "        adf_results['Critical Value (5%)'].append(critical_values['5%'])\n",
    "\n",
    "        adf_results['Critical Value (10%)'].append(critical_values['10%'])\n",
    "\n",
    "        adf_results['Стационарность'].append(stationarity)\n",
    "\n",
    "    \n",
    "\n",
    "    # Преобразование словаря в DataFrame и отображение результатов\n",
    "\n",
    "    adf_results_df = pd.DataFrame(adf_results)\n",
    "\n",
    "    return adf_results_df\n",
    "\n",
    "\n",
    "\n",
    "# Выполнение теста ADF и вывод результатов\n",
    "\n",
    "adf_results_df = perform_adf_test(filled_data_dict)\n",
    "\n",
    "print(\"Результаты теста ADF для всех активов:\")\n",
    "\n",
    "display(adf_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 9. Проверка автокорреляции (ACF и PACF)\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "# Функция для анализа автокорреляции с ACF и PACF\n",
    "\n",
    "def autocorrelation_analysis(data, max_lags=20, significance_level=0.05):\n",
    "\n",
    "    acf_results = {\n",
    "\n",
    "        'Тикер': [],\n",
    "\n",
    "        'Название': [],\n",
    "\n",
    "        'Автокорреляция': []\n",
    "\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    for ticker, df in data.items():\n",
    "\n",
    "        company_name = full_names.get(ticker, 'Unknown')\n",
    "\n",
    "        \n",
    "\n",
    "        # Проверка на наличие достаточного количества данных для анализа автокорреляции\n",
    "\n",
    "        if len(df['Adj Close'].dropna()) < max_lags:\n",
    "\n",
    "            print(f\"Недостаточно данных для анализа {ticker} ({company_name}). Пропускаем.\")\n",
    "\n",
    "            acf_results['Тикер'].append(ticker)\n",
    "\n",
    "            acf_results['Название'].append(company_name)\n",
    "\n",
    "            acf_results['Автокорреляция'].append(\"Недостаточно данных\")\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Построение ACF и PACF графиков\n",
    "\n",
    "            fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "            plot_acf(df['Adj Close'].dropna(), lags=max_lags, alpha=significance_level, ax=axes[0])\n",
    "\n",
    "            axes[0].set_title(f'Автокорреляция (ACF) - {company_name} ({ticker})')\n",
    "\n",
    "            plot_pacf(df['Adj Close'].dropna(), lags=max_lags, alpha=significance_level, ax=axes[1])\n",
    "\n",
    "            axes[1].set_title(f'Частичная автокорреляция (PACF) - {company_name} ({ticker})')\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "            # Проверка на автокорреляцию\n",
    "\n",
    "            adf_test = adfuller(df['Adj Close'].dropna())\n",
    "\n",
    "            p_value = adf_test[1]\n",
    "\n",
    "            is_autocorrelated = \"Имеется автокорреляция\" if p_value < significance_level else \"Нет автокорреляции\"\n",
    "\n",
    "            \n",
    "\n",
    "            # Сохранение результатов\n",
    "\n",
    "            acf_results['Тикер'].append(ticker)\n",
    "\n",
    "            acf_results['Название'].append(company_name)\n",
    "\n",
    "            acf_results['Автокорреляция'].append(is_autocorrelated)\n",
    "\n",
    "        \n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f\"Ошибка при обработке {ticker} ({company_name}): {e}\")\n",
    "\n",
    "            acf_results['Тикер'].append(ticker)\n",
    "\n",
    "            acf_results['Название'].append(company_name)\n",
    "\n",
    "            acf_results['Автокорреляция'].append(\"Ошибка анализа\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Преобразование результатов в таблицу и отображение\n",
    "\n",
    "    acf_results_df = pd.DataFrame(acf_results)\n",
    "\n",
    "    display(acf_results_df)\n",
    "\n",
    "\n",
    "\n",
    "# Выполнение анализа автокорреляции\n",
    "\n",
    "autocorrelation_analysis(filled_data_dict, max_lags=20, significance_level=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 10. Устранение нестационарности, автокорреляции и сезонности. Возведение в логарифм и перепроверка стацционарности\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "\n",
    "# Параметры анализа\n",
    "\n",
    "window_size = 365  # Rolling window size (in days)\n",
    "\n",
    "analysis_period = \"Период анализа: с {start_date} по {end_date}\"\n",
    "\n",
    "\n",
    "\n",
    "# Получаем даты начала и конца для анализа (предполагаем, что данные заполнены по каждому активу)\n",
    "\n",
    "start_date = filled_data_dict[list(filled_data_dict.keys())[0]].index.min().strftime('%Y-%m-%d')\n",
    "\n",
    "end_date = filled_data_dict[list(filled_data_dict.keys())[0]].index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "# Дефляция данных и вычисление скользящих метрик\n",
    "\n",
    "log_data_dict = {}\n",
    "\n",
    "rolling_metrics_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "for ticker, data in filled_data_dict.items():\n",
    "\n",
    "    # Логарифмируем данные\n",
    "\n",
    "    log_data = np.log(data['Adj Close'])\n",
    "\n",
    "    log_data_dict[ticker] = log_data\n",
    "\n",
    "\n",
    "\n",
    "    # Вычисляем скользящее среднее и стандартное отклонение\n",
    "\n",
    "    rolling_mean = log_data.rolling(window=window_size).mean()\n",
    "\n",
    "    rolling_std = log_data.rolling(window=window_size).std()\n",
    "\n",
    "    \n",
    "\n",
    "    rolling_metrics_dict[ticker] = pd.DataFrame({\n",
    "\n",
    "        'log_price': log_data,\n",
    "\n",
    "        'rolling_mean': rolling_mean,\n",
    "\n",
    "        'rolling_std': rolling_std\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    # Построение графиков\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(log_data, label=f'{full_names[ticker]} ({ticker}) Log Adj Close', color='blue')\n",
    "\n",
    "    plt.plot(rolling_mean, label='Rolling Mean (365 days)', color='green')\n",
    "\n",
    "    plt.plot(rolling_std, label='Rolling Std Dev (365 days)', color='red')\n",
    "\n",
    "    plt.title(f\"{full_names[ticker]} ({ticker}) - Log Adj Close, Rolling Mean and Std Dev\\n{analysis_period.format(start_date=start_date, end_date=end_date)}\")\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Тест на автокорреляцию и визуализация ACF/PACF\n",
    "\n",
    "acf_pacf_results = []\n",
    "\n",
    "\n",
    "\n",
    "for ticker, log_data in log_data_dict.items():\n",
    "\n",
    "    # ADF тест\n",
    "\n",
    "    adf_test = adfuller(log_data.dropna())\n",
    "\n",
    "    adf_result = 'Стационарен' if adf_test[1] < 0.05 else 'Нестационарен'\n",
    "\n",
    "    \n",
    "\n",
    "    # Сохраняем результаты теста\n",
    "\n",
    "    acf_pacf_results.append({\n",
    "\n",
    "        'Актив': f\"{full_names[ticker]} ({ticker})\",\n",
    "\n",
    "        'ADF Test Statistic': adf_test[0],\n",
    "\n",
    "        'p-value': adf_test[1],\n",
    "\n",
    "        'Critical Values (1%)': adf_test[4]['1%'],\n",
    "\n",
    "        'Critical Values (5%)': adf_test[4]['5%'],\n",
    "\n",
    "        'Critical Values (10%)': adf_test[4]['10%'],\n",
    "\n",
    "        'Result': adf_result\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    # Построение ACF и PACF\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    fig.suptitle(f'ACF and PACF for {full_names[ticker]} ({ticker}) - Log Data\\n{analysis_period.format(start_date=start_date, end_date=end_date)}')\n",
    "\n",
    "    plot_acf(log_data.dropna(), ax=axes[0], lags=40, alpha=0.05)\n",
    "\n",
    "    plot_pacf(log_data.dropna(), ax=axes[1], lags=40, alpha=0.05)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Таблица с результатами теста ADF\n",
    "\n",
    "adf_results_df = pd.DataFrame(acf_pacf_results)\n",
    "\n",
    "display(adf_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение дифференцирования к ряду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Применение дифференцирования\n",
    "\n",
    "diff_data_dict = {ticker: data.diff().dropna() for ticker, data in log_data_dict.items()}\n",
    "\n",
    "\n",
    "\n",
    "# Параметры для rolling метрик\n",
    "\n",
    "rolling_window = 365  # Например, 365 дней\n",
    "\n",
    "\n",
    "\n",
    "# Построение графиков для каждого актива после дифференцирования\n",
    "\n",
    "for ticker, diff_data in diff_data_dict.items():\n",
    "\n",
    "    asset_name = full_names[ticker]\n",
    "\n",
    "    \n",
    "\n",
    "    # Скользящее среднее и стандартное отклонение для дифференцированных данных\n",
    "\n",
    "    roll_mean = diff_data.rolling(window=rolling_window).mean()\n",
    "\n",
    "    roll_std = diff_data.rolling(window=rolling_window).std()\n",
    "\n",
    "    \n",
    "\n",
    "    # График дифференцированных данных и скользящих метрик\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(diff_data, color='blue', label=f'{ticker}_log_diff')\n",
    "\n",
    "    plt.plot(roll_mean, color='green', label=f'roll_mean_log_diff ({rolling_window} дней)')\n",
    "\n",
    "    plt.plot(roll_std, color='red', label=f'roll_std_log_diff ({rolling_window} дней)')\n",
    "\n",
    "    plt.title(f'{asset_name} (Дифференцированные логарифмы)')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel('Дата')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    # Тест ADF на стационарность\n",
    "\n",
    "    adf_result = adfuller(diff_data.dropna())\n",
    "\n",
    "    print(f\"ADF Test для {asset_name} ({ticker}):\")\n",
    "\n",
    "    print(f\" - Статистика теста: {adf_result[0]:.4f}\")\n",
    "\n",
    "    print(f\" - p-значение: {adf_result[1]:.4f}\")\n",
    "\n",
    "    print(\" - Критические значения:\")\n",
    "\n",
    "    for key, value in adf_result[4].items():\n",
    "\n",
    "        print(f\"     {key}: {value:.4f}\")\n",
    "\n",
    "    if adf_result[1] < 0.05:\n",
    "\n",
    "        print(f\"Результат: Временной ряд {asset_name} стационарен.\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f\"Результат: Временной ряд {asset_name} нестационарен.\")\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "    # Построение графиков автокорреляции и частичной автокорреляции\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "    fig.suptitle(f'{asset_name} (Автокорреляция и частичная автокорреляция)')\n",
    "\n",
    "\n",
    "\n",
    "    sns.set_style(\"darkgrid\")\n",
    "\n",
    "    sns.lineplot(x=range(len(acf(diff_data.dropna(), nlags=40))), y=acf(diff_data.dropna(), nlags=40), ax=axes[0], marker='o')\n",
    "\n",
    "    sns.lineplot(x=range(len(pacf(diff_data.dropna(), nlags=40))), y=pacf(diff_data.dropna(), nlags=40), ax=axes[1], marker='o')\n",
    "\n",
    "    \n",
    "\n",
    "    axes[0].set_title(\"Autocorrelation\")\n",
    "\n",
    "    axes[1].set_title(\"Partial Autocorrelation\")\n",
    "\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 11. Вывод данных после дифференцирования поквартально (необходимо для дальнейшего анализа влияния вместе с макроэкономическими данными)\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# A) Поквартальный анализ скорректированных данных для всех активов\n",
    "\n",
    "def quarterly_analysis(data, ticker, full_name):\n",
    "\n",
    "    # Применение данных из diff_data_dict (уже дифференцированные)\n",
    "\n",
    "    quarterly_data = data.resample('Q').mean()\n",
    "\n",
    "\n",
    "\n",
    "    # Визуализация поквартальных данных\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(quarterly_data.index, quarterly_data, label=f'{full_name} ({ticker}) Quarterly Adjusted Close')\n",
    "\n",
    "    plt.title(f'Поквартальный анализ скорректированных данных для {full_name} ({ticker})')\n",
    "\n",
    "    plt.xlabel('Дата')\n",
    "\n",
    "    plt.ylabel('Цена (дифференцированные данные)')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Новый словарь для хранения поквартальных данных\n",
    "\n",
    "quarterly_diff_data_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# Применение поквартального анализа для всех активов\n",
    "\n",
    "for ticker, data in diff_data_dict.items():\n",
    "\n",
    "    full_name = full_names.get(ticker, ticker)  # Получаем полное название актива\n",
    "\n",
    "    quarterly_diff_data_dict[ticker] = data.resample('Q').mean()  # Сохраняем поквартальные данные в словарь\n",
    "\n",
    "    quarterly_analysis(data, ticker, full_name)\n",
    "\n",
    "\n",
    "\n",
    "# B) Поквартальный анализ по группам активов\n",
    "\n",
    "def group_quarterly_analysis(group_name, tickers):\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "\n",
    "    for ticker in tickers:\n",
    "\n",
    "        data = diff_data_dict[ticker]\n",
    "\n",
    "        full_name = full_names.get(ticker, ticker)  # Полное название актива\n",
    "\n",
    "        quarterly_data = data.resample('Q').mean()\n",
    "\n",
    "        plt.plot(quarterly_data.index, quarterly_data, label=f'{full_name} ({ticker})')\n",
    "\n",
    "\n",
    "\n",
    "    plt.title(f'{group_name} Group (Quarterly Differenced Data)')\n",
    "\n",
    "    plt.xlabel('Дата')\n",
    "\n",
    "    plt.ylabel('Цена (дифференцированные данные)')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Применение поквартального анализа для каждой группы активов\n",
    "\n",
    "for group, tickers in asset_classes.items():\n",
    "\n",
    "    group_quarterly_analysis(group, tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# 12. Анализ влияния\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт данных с помощью fred api. Macrodata\n",
    "'''\n",
    "Этот код загружает и объединяет макроэкономические данные из базы данных FRED (Federal Reserve Economic Data) по следующим показателям: ВВП, уровень безработицы, индекс потребительских цен (CPI), индекс промышленного производства (PMI), процентная ставка, торговый баланс, экспорт и импорт. Данные собираются с 1990 года до текущей даты, после чего объединяются в один `DataFrame` `macro_data` для анализа. В конце отображаются последние строки (с помощью `print(macro_data.tail())`) для предварительного просмотра данных.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from scipy import stats\n",
    "from fredapi import Fred\n",
    "\n",
    "\n",
    "# Fred API key\n",
    "fred = Fred(api_key='2409f89109db1e4dcb431b6ca50f575e')\n",
    "\n",
    "# Устанавливаем временной диапазон\n",
    "start = datetime.datetime(1990, 1, 1)  # Установим начальную дату как можно раньше\n",
    "end = datetime.datetime.now()\n",
    "\n",
    "# Получение данных о ВВП\n",
    "gdp = fred.get_series('GDP', start, end)\n",
    "\n",
    "# Получение данных об уровне безработицы\n",
    "unemployment = fred.get_series('UNRATE', start, end)\n",
    "\n",
    "# Получение данных об индексе потребительских цен (CPI)\n",
    "cpi = fred.get_series('CPIAUCSL', start, end)\n",
    "\n",
    "# Получение данных об индексах промышленного производства (PMI)\n",
    "pmi = fred.get_series('INDPRO', start, end)\n",
    "\n",
    "# Получение данных о процентных ставках\n",
    "interest_rate = fred.get_series('FEDFUNDS', start, end)\n",
    "\n",
    "# Получение данных о торговом балансе\n",
    "trade_balance = fred.get_series('BOPGSTB', start, end)\n",
    "\n",
    "# Получение данных об объемах экспорта и импорта\n",
    "export_data = fred.get_series('NETEXP', start, end)  # Объем экспорта\n",
    "import_data = fred.get_series('IMPGS', start, end)  # Объем импорта\n",
    "\n",
    "# Преобразование данных в DataFrame\n",
    "macro_data = pd.concat([gdp, unemployment, cpi, pmi, interest_rate, trade_balance, export_data, import_data], axis=1)\n",
    "macro_data.columns = ['GDP', 'Unemployment Rate', 'CPI', 'PMI', 'Interest Rate', 'Trade Balance', 'Export', 'Import']\n",
    "\n",
    "# Вывод полученных данных\n",
    "print(macro_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ресемплинг поквартально так как на сайте данные даются поквартально \n",
    "'''\n",
    "Код извлекает ключевые макроэкономические показатели (ВВП, безработица, CPI, PMI, процентные ставки, торговый баланс, экспорт, импорт), агрегируя их по кварталам для сглаживания данных. Затем он объединяет эти показатели в один DataFrame для удобного анализа квартальной динамики и сравнения индикаторов.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение данных о ВВП\n",
    "gdp = fred.get_series('GDP', start, end).resample('Q').mean()\n",
    "\n",
    "# Получение данных об уровне безработицы\n",
    "unemployment = fred.get_series('UNRATE', start, end).resample('Q').mean()\n",
    "\n",
    "# Получение данных об индексе потребительских цен (CPI)\n",
    "cpi = fred.get_series('CPIAUCSL', start, end).resample('Q').mean()\n",
    "\n",
    "# Получение данных об индексах промышленного производства (PMI)\n",
    "pmi = fred.get_series('INDPRO', start, end).resample('Q').mean()\n",
    "\n",
    "# Получение данных о процентных ставках\n",
    "interest_rate = fred.get_series('FEDFUNDS', start, end).resample('Q').mean()\n",
    "\n",
    "# Получение данных о торговом балансе\n",
    "trade_balance = fred.get_series('BOPGSTB', start, end).resample('Q').mean()\n",
    "\n",
    "# Получение данных об объемах экспорта и импорта\n",
    "export_data = fred.get_series('NETEXP', start, end).resample('Q').mean()  # Объем экспорта\n",
    "import_data = fred.get_series('IMPGS', start, end).resample('Q').mean()  # Объем импорта\n",
    "\n",
    "# Преобразование данных в DataFrame\n",
    "macro_data = pd.concat([gdp, unemployment, cpi, pmi, interest_rate, trade_balance, export_data, import_data], axis=1)\n",
    "macro_data.columns = ['GDP', 'Unemployment Rate', 'CPI', 'PMI', 'Interest Rate', 'Trade Balance', 'Export', 'Import']\n",
    "\n",
    "# Вывод полученных данных\n",
    "print(macro_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================================\n",
    "# 13. Описание данных\n",
    "# =============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = macro_data.describe()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================================\n",
    "# 14. Проверка на наличие выбросов\n",
    "# ==============================================================\n",
    "\n",
    "'''\n",
    "Код вычисляет **Z-оценки** для данных в `macro_data`, чтобы определить выбросы: значения, которые более чем на 3 стандартных отклонения отличаются от среднего. Значения `True` в выводе `outliers` указывают на наличие выбросов в соответствующих местах.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(macro_data))\n",
    "outliers = (z_scores > 3)  # Используем Z-Score для определения выбросов\n",
    "print(\"Выбросы (значения True указывают на наличие выбросов):\")\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================================\n",
    "# 15. Визуализация временных рядов\n",
    "# =============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "for i, col in enumerate(macro_data.columns):\n",
    "    plt.subplot(4, 2, i + 1)\n",
    "    plt.plot(macro_data[col])\n",
    "    plt.title(col)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "По графикам выше можно сделать следующие статистические выводы:\n",
    "1. **GDP (ВВП)**: ВВП показывает стабильный рост с 1990 года, с резкими провалами в периоды экономических кризисов, таких как 2008 и 2020 годы, что указывает на общую тенденцию к росту экономики.\n",
    "2. **Unemployment Rate (Уровень безработицы)**: Уровень безработицы подвержен циклическим колебаниям, с резкими скачками в периоды экономических кризисов (особенно заметен пик в 2020 году), после чего он постепенно снижается.\n",
    "3. **CPI (Индекс потребительских цен)**: CPI растет устойчиво на протяжении всего периода, что свидетельствует о долгосрочной инфляции.\n",
    "4. **PMI (Индекс промышленного производства)**: PMI показывает положительную динамику до 2000-х годов, после чего наблюдаются колебания. Ярко выраженные падения PMI совпадают с экономическими кризисами (например, в 2008 и 2020 годах), указывая на чувствительность промышленного производства к экономическим условиям.\n",
    "5. **Interest Rate (Процентные ставки)**: Процентные ставки колебались, снижаясь до минимальных уровней в 2010-х годах и снова повышаясь в последние годы, что может быть связано с борьбой с инфляцией и мерами поддержки экономики.\n",
    "6. **Trade Balance (Торговый баланс)**: Торговый баланс показывает общий нисходящий тренд, что может свидетельствовать о росте дефицита торгового баланса страны.\n",
    "7. **Export (Экспорт)**: Экспорт показывает тенденцию к снижению после небольшого роста в 1990-х годах, что может указывать на снижение внешней конкурентоспособности.\n",
    "8. **Import (Импорт)**: Импорт стабильно растет с 1990 года, что может указывать на рост внутреннего потребления и зависимости от иностранных товаров.\n",
    "\n",
    "В целом, графики показывают долгосрочные тенденции в ключевых экономических показателях, а также влияние глобальных экономических кризисов на безработицу, промышленное производство и процентные ставки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================================\n",
    "# 16. Тесты на стационарность, автокорреляцию и сезонность\n",
    "# =============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in macro_data.columns:\n",
    "    adf_test = adfuller(macro_data[col].dropna())\n",
    "    kpss_test = kpss(macro_data[col].dropna(), regression='c')\n",
    "    \n",
    "    print(f\"\\nТесты для {col}:\")\n",
    "    print(f\"ADF Statistic: {adf_test[0]}, p-value: {adf_test[1]}\")\n",
    "    print(f\"KPSS Statistic: {kpss_test[0]}, p-value: {kpss_test[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "1. **GDP**:\n",
    "- ADF Statistic: 3.92, p-value: 1.0\n",
    "- KPSS Statistic: 2.01, p-value: 0.01\n",
    "- **Вывод**: Невозможно отклонить H0 по ADF, ряд не стационарен. H0 по KPSS отклоняется, что подтверждает нестационарность.\n",
    "\n",
    "2. **Unemployment Rate**:\n",
    "- ADF Statistic: -3.14, p-value: 0.024\n",
    "- KPSS Statistic: 0.18, p-value: 0.1\n",
    "- **Вывод**: ADF указывает на стационарность (H0 отклоняется), а KPSS не отклоняет H0, указывая на стационарность. Противоречивые результаты, но в целом можно считать ряд стационарным.\n",
    "\n",
    "3. **CPI**:\n",
    "- ADF Statistic: 1.90, p-value: 0.999\n",
    "- KPSS Statistic: 2.05, p-value: 0.01\n",
    "- **Вывод**: Оба теста показывают, что ряд не стационарен.\n",
    "\n",
    "4. **PMI**:\n",
    "- ADF Statistic: -1.98, p-value: 0.295\n",
    "- KPSS Statistic: 1.64, p-value: 0.01\n",
    "- **Вывод**: Невозможно отклонить H0 по ADF, ряд не стационарен, а KPSS отклоняет H0, подтверждая нестационарность.\n",
    "\n",
    "5. **Interest Rate**:\n",
    "- ADF Statistic: -3.23, p-value: 0.018\n",
    "- KPSS Statistic: 1.03, p-value: 0.01\n",
    "- **Вывод**: ADF указывает на стационарность (H0 отклоняется), а KPSS указывает на нестационарность. Можно считать ряд стационарным.\n",
    "\n",
    "6. **Trade Balance**:\n",
    "- ADF Statistic: -1.33, p-value: 0.616\n",
    "- KPSS Statistic: 1.32, p-value: 0.01\n",
    "- **Вывод**: Невозможно отклонить H0 по ADF, ряд не стационарен, а KPSS подтверждает нестационарность.\n",
    "\n",
    "7. **Export**:\n",
    "- ADF Statistic: -1.14, p-value: 0.701\n",
    "- KPSS Statistic: 1.51, p-value: 0.01\n",
    "- **Вывод**: Невозможно отклонить H0 по ADF, ряд не стационарен, а KPSS подтверждает нестационарность.\n",
    "\n",
    "8. **Import**:\n",
    "- ADF Statistic: -0.15, p-value: 0.944\n",
    "- KPSS Statistic: 2.03, p-value: 0.01\n",
    "- **Вывод**: Невозможно отклонить H0 по ADF, ряд не стационарен, а KPSS подтверждает нестационарность.\n",
    "\n",
    "### Общие выводы:\n",
    "- Большинство временных рядов (GDP, CPI, PMI, Trade Balance, Export, Import) показывают нестационарность.\n",
    "- Уровень безработицы и процентная ставка имеют смешанные результаты, но можно считать их стационарными на основании ADF.\n",
    "- Для анализа данных, возможно, потребуется трансформация (например, дифференцирование) для достижения стационарности, что является необходимым шагом перед дальнейшим моделированием."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================================\n",
    "# 17. Корректировка данных (если необходимо)\n",
    "# ==============================================================\n",
    "\n",
    "'''\n",
    "Разностное преобразование применено для достижения стационарности временных рядов. В результате были получены скорректированные данные, которые позволяют устранить тренды и сезонные колебания, что важно для дальнейшего анализа и моделирования. Результаты разностного преобразования показаны в последней части таблицы скорректированных данных.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разностное преобразование для достижения стационарности\n",
    "adjusted_macrodata = macro_data.diff().dropna()\n",
    "print(\"\\nСкорректированные данные (разностное преобразование):\")\n",
    "print(adjusted_macrodata.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================================\n",
    "# 18. Аналитика\n",
    "# =============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_macrodata.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "Данные по макроданным доступны с 1992-06-30. В связи с этим, с целью анализа влияния и проведения линейной регрессии, мы привели данные по активам и макроданным в единый формат с одинаковым началом временного периода. Помимо синхронизации временных интервалов и ограничения данных общим временным диапазоном, было произведено преобразование данных по активам в общий DataFrame. На основе этого была построена корреляционная матрица в разрезе активов и макроданных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Корреляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Синхронизация временных интервалов\n",
    "# Находим общий диапазон для всех данных\n",
    "\n",
    "common_start = max(min(adjusted_macrodata.index), min(min(df.index) for df in quarterly_diff_data_dict.values()))\n",
    "common_end = min(max(adjusted_macrodata.index), max(max(df.index) for df in quarterly_diff_data_dict.values()))\n",
    "\n",
    "# Ограничиваем данные общим временным диапазоном\n",
    "\n",
    "macrodata_aligned = adjusted_macrodata.loc[common_start:common_end]\n",
    "asset_data_aligned = {ticker: df.loc[common_start:common_end] for ticker, df in quarterly_diff_data_dict.items()}\n",
    "\n",
    "# Преобразование данных по активам в общий DataFrame\n",
    "\n",
    "combined_asset_data = pd.concat(asset_data_aligned.values(), axis=1)\n",
    "combined_asset_data.columns = [f\"{ticker} ({full_names.get(ticker, ticker)})\" for ticker in asset_data_aligned.keys()]\n",
    "\n",
    "# 2. Приведение к единому формату\n",
    "# Нормализуем для корректного анализа корреляции\n",
    "\n",
    "normalized_asset_data = (combined_asset_data - combined_asset_data.mean()) / combined_asset_data.std()\n",
    "normalized_macrodata = (macrodata_aligned - macrodata_aligned.mean()) / macrodata_aligned.std()\n",
    "\n",
    "# Соединяем активы и макроданные для анализа корреляции\n",
    "\n",
    "data_for_correlation = pd.concat([normalized_asset_data, normalized_macrodata], axis=1).dropna()\n",
    "\n",
    "# 3. Построение корреляционной матрицы\n",
    "\n",
    "# Вычисляем корреляцию\n",
    "\n",
    "correlation_matrix = data_for_correlation.corr().loc[normalized_asset_data.columns, normalized_macrodata.columns]\n",
    "\n",
    "# Визуализация тепловой карты корреляций\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", cbar_kws={'label': 'Correlation Coefficient'}, square=True, annot=False)\n",
    "plt.title(f\"Корреляционная матрица между активами и макроэкономическими показателями (Период анализа: {common_start.date()} - {common_end.date()})\")\n",
    "plt.xlabel(\"Макроэкономические показатели\")\n",
    "plt.ylabel(\"Активы (с полными названиями)\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Вывод таблицы корреляций для анализа с display\n",
    "# Таблица корреляций\n",
    "\n",
    "correlation_table = correlation_matrix.copy()\n",
    "display(correlation_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "На основе данной таблицы корреляции между активами и макроэкономическими показателями можно сделать несколько выводов: \n",
    "1. **Чувствительность акций к макроэкономическим показателям**: - Акции технологических компаний, таких как Apple (AAPL), Microsoft (MSFT), NVIDIA (NVDA) и Amazon (AMZN), показывают отрицательную корреляцию с процентными ставками. Это значит, что повышение процентных ставок негативно влияет на эти компании, так как более высокие ставки могут повысить затраты на заимствования и снизить их рыночную стоимость. \n",
    "2. **Влияние инфляции (ИПЦ) на сырьевые товары**: - Сырьевые товары, такие как нефть (CL=F) и золото (GC=F), имеют положительную корреляцию с индексом потребительских цен (ИПЦ). Это говорит о том, что при росте инфляции цены на сырьевые товары также имеют тенденцию к росту, поскольку они выступают в качестве защиты от инфляции. \n",
    "3. **Взаимосвязь валютных курсов и процентных ставок**: - Валютные пары, такие как EURUSD=X (евро/доллар США) и USDJPY=X (доллар США/японская иена), имеют положительную корреляцию с процентными ставками, что подтверждает тенденцию укрепления валют при повышении ставок. Это объясняется тем, что более высокие ставки привлекают иностранные инвестиции, повышая спрос на валюту. \n",
    "4. **Зависимость фондовых индексов от экономических условий**: - Основные фондовые индексы, такие как S&P 500 (^GSPC) и Dow Jones (^DJI), имеют положительную корреляцию с ВВП и отрицательную — с уровнем безработицы. Это подтверждает, что рост экономики и снижение безработицы поддерживают фондовые рынки, так как в таких условиях растут корпоративные прибыли и улучшаются ожидания инвесторов. \n",
    "5. **Торговый баланс и экспортно-импортные показатели**: - Для таких компаний, как Tesla (TSLA) и Intel (INTC), наблюдается отрицательная корреляция с торговым балансом и положительная корреляция с показателями экспорта. Это говорит о том, что для таких экспортоориентированных компаний увеличение объемов торговли и благоприятные внешнеэкономические условия способствуют их росту. \n",
    "\n",
    "Эти выводы позволяют понять, как различные активы реагируют на изменения в экономических показателях и каким образом макроэкономическая ситуация может повлиять на их динамику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "# 1. Синхронизация временных интервалов\n",
    "\n",
    "# Определение общего временного диапазона\n",
    "\n",
    "common_start = max(min(adjusted_macrodata.index), min(min(df.index) for df in quarterly_diff_data_dict.values()))\n",
    "\n",
    "common_end = min(max(adjusted_macrodata.index), max(max(df.index) for df in quarterly_diff_data_dict.values()))\n",
    "\n",
    "\n",
    "\n",
    "# Ограничиваем данные общим временным диапазоном\n",
    "\n",
    "macrodata_aligned = adjusted_macrodata.loc[common_start:common_end]\n",
    "\n",
    "asset_data_aligned = {ticker: df.loc[common_start:common_end] for ticker, df in quarterly_diff_data_dict.items()}\n",
    "\n",
    "\n",
    "\n",
    "# Создание таблицы для значимых макроэкономических факторов\n",
    "\n",
    "significant_factors_summary = pd.DataFrame(columns=['Asset', 'Significant Macroeconomic Factors'])\n",
    "\n",
    "\n",
    "\n",
    "# 2. Выполнение регрессионного анализа для каждого актива\n",
    "\n",
    "for ticker, data in asset_data_aligned.items():\n",
    "\n",
    "    asset_name = full_names.get(ticker, ticker)\n",
    "\n",
    "    \n",
    "\n",
    "    # Объединение макроэкономических данных и данных актива\n",
    "\n",
    "    combined_data = pd.concat([data, macrodata_aligned], axis=1).dropna()\n",
    "\n",
    "    \n",
    "\n",
    "    # Макроэкономические показатели в качестве независимых переменных\n",
    "\n",
    "    X = combined_data[macrodata_aligned.columns]\n",
    "\n",
    "    X = sm.add_constant(X)  # добавляем константу для регрессии\n",
    "\n",
    "    y = combined_data['Adj Close']  # зависимая переменная - актив\n",
    "\n",
    "    \n",
    "\n",
    "    # Построение регрессионной модели\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    results_summary = model.summary2().tables[1]  # извлекаем таблицу коэффициентов\n",
    "\n",
    "    \n",
    "\n",
    "    # Вывод таблицы с результатами регрессии\n",
    "\n",
    "    print(f\"\\nРегрессионный анализ для {asset_name} ({ticker})\")\n",
    "\n",
    "    print(f\"Период анализа: {common_start.date()} - {common_end.date()}\")\n",
    "\n",
    "    display(results_summary)\n",
    "\n",
    "    \n",
    "\n",
    "    # 3. Генерация выводов на основе значимых факторов\n",
    "\n",
    "    significant_factors = results_summary[results_summary['P>|t|'] < 0.05].index.tolist()\n",
    "\n",
    "    \n",
    "\n",
    "    # Добавление вывода\n",
    "\n",
    "    if significant_factors:\n",
    "\n",
    "        print(f\"Значимые макроэкономические факторы для {asset_name} ({ticker}): {', '.join(significant_factors[1:])}\")\n",
    "\n",
    "        # Добавление в сводную таблицу с использованием pd.concat\n",
    "\n",
    "        significant_factors_summary = pd.concat([\n",
    "\n",
    "            significant_factors_summary, \n",
    "\n",
    "            pd.DataFrame({'Asset': [f\"{asset_name} ({ticker})\"], \n",
    "\n",
    "                          'Significant Macroeconomic Factors': [', '.join(significant_factors[1:])]})\n",
    "\n",
    "        ], ignore_index=True)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f\"Для {asset_name} ({ticker}) не выявлено значимых макроэкономических факторов на уровне значимости 5%.\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. Отображение сводной таблицы значимых макроэкономических факторов\n",
    "\n",
    "print(\"\\nСводная таблица значимых макроэкономических факторов для каждого актива:\")\n",
    "\n",
    "display(significant_factors_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "Эта таблица отражает результаты регрессионного анализа и показывает значимые макроэкономические факторы, влияющие на различные активы. Каждый актив в списке ассоциируется с одним или несколькими макроэкономическими показателями, которые имеют статистически значимое влияние на его поведение.\n",
    "1. **Акции крупных компаний**: \n",
    "- Для таких компаний, как **Apple (AAPL)** и **NVIDIA (NVDA)**, значимым фактором оказался уровень безработицы. Это указывает на зависимость их деятельности от состояния рынка труда, что может быть связано с потребительскими расходами и спросом. \n",
    "- **Meta Platforms (META)** также чувствительна к уровню безработицы, а **Walmart (WMT)** – к уровню безработицы и индексу деловой активности (PMI), что указывает на высокую зависимость от экономической активности и покупательской способности. \n",
    "2. **Сырьевые товары**: \n",
    "- Цены на **нефть (Crude Oil Futures, CL=F)**, **медь (Copper Futures, HG=F)** и **сою (Soybean Futures, ZS=F)** зависят от показателей импорта, что может свидетельствовать о влиянии мирового спроса и торговых потоков на цены этих товаров. \n",
    "- **Золото (Gold Futures, GC=F)** чувствительно к уровню инфляции (CPI), что подтверждает его роль как актива для хеджирования против инфляции. **Серебро (Silver Futures, SI=F)** также коррелирует с CPI, а еще — с торговым балансом и экспортом, что указывает на его зависимость от глобальных экономических факторов. \n",
    "3. **Фондовые индексы**: \n",
    "- Основные индексы, такие как **S&P 500 (^GSPC)**, **Dow Jones (^DJI)** и **NASDAQ Composite (^IXIC)**, показывают значимую зависимость от уровня безработицы и инфляции (CPI). Это подтверждает их чувствительность к общей экономической ситуации и условиям на рынке труда. \n",
    "- **Индекс волатильности (VIX)**, который отражает ожидания инвесторов по колебаниям рынка, также значимо зависит от уровня безработицы и инфляции. \n",
    "4. **Гособлигации и ставки**: \n",
    "- Для краткосрочных облигаций, таких как **13-недельные казначейские векселя (^IRX)**, значимым фактором является процентная ставка, что логично, учитывая, что их доходность тесно связана с краткосрочными изменениями денежно-кредитной политики. \n",
    "- Долгосрочные облигации, такие как **30-летние казначейские облигации (^TYX)**, зависят от уровня безработицы, что указывает на влияние ожиданий по экономическому росту на их доходность. \n",
    "5. **Валютные пары**: \n",
    "- Для валют, таких как **евро/доллар США (EURUSD=X)** и **японская иена/доллар США (JPYUSD=X)**, значимыми факторами являются экспорт и импорт, что свидетельствует об их чувствительности к торговым потокам. \n",
    "- Для **китайского юаня (CNYUSD=X)** и **сингапурского доллара (SGDUSD=X)** значимыми факторами являются торговый баланс, экспорт и импорт, что подтверждает их зависимость от внешнеэкономической торговли и политики. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
