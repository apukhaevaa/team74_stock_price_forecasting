## Переход к рынку Бразилии ##

Переход к анализу бразильских активов продиктован стремлением расширить спектр рыночных условий, в которых мы проверяем работоспособность и качество наших моделей. Изначально мы фокусировались на наиболее ликвидных и глобально значимых инструментах – американских акциях, сырьевых фьючерсах, государственных облигациях развитых стран, – что создавало относительно предсказуемую и хорошо изученную среду. Однако такие активы, несмотря на их ключевое значение в мировой финансовой системе, не всегда позволяют оценить устойчивость и адаптивность наших подходов к нетривиальным сценариям. 
 Бразильский рынок, являясь одним из крупнейших и наиболее динамичных в Южной Америке, представляет собой пример развивающейся экономики с уникальными структурными особенностями. Инвестиционный климат в Бразилии формируется под влиянием целого ряда местных факторов, таких как специфические политические риски, характерная для региона инфляционная динамика, поведенческие паттерны местных инвесторов, а также иная степень информационной эффективности и доступности данных. Кроме того, бразильский фондовый рынок и долговые инструменты имеют тенденцию к более высокой волатильности и менее предсказуемой реакции на внешние шоки по сравнению с классическими «якорными» активами развитых стран.

Таким образом, анализ бразильских инструментов выступает тестом на универсальность моделей: если наша методология машинного и глубокого обучения успешно справляется с прогнозированием под столь отличающимися рыночными условиями, значит она обладает большим потенциалом к обобщению. 

# Анализ и выводы по результатам экспоненциального сглаживания

## 1. Этапы анализа

### 1.1 Предварительная обработка данных
- **Описание данных**: Анализ начался с загрузки набора данных акций, содержащего столбцы `ticker`, `price_date`, `close`, `adjusted_close` и другие метрики. Данные охватывают период с 2000 года по 2024 год.
- **Выявление пропусков и выбросов**: Выполнена проверка на пропуски в столбце `adjusted_close`. Пропуски заменены медианными значениями. Выбросы были оценены с использованием межквартильного размаха (IQR): умеренные (1.5 IQR) и экстремальные (3 IQR).

### 1.2 Ресемплирование данных
- Для каждого тикера выполнено ресемплирование на недельной основе, что позволило сократить объём данных и сделать их более однородными для анализа временных рядов.

### 1.3 Разделение на тренировочную и тестовую выборки
- Данные разделены в пропорции 80/20 для тренировочной и тестовой выборок. Это обеспечило наличие данных для обучения модели и независимой проверки её качества.

### 1.4 Применение методов сглаживания
- **Простое экспоненциальное сглаживание (SES)**: Метод применён для получения сглаженных значений временных рядов и прогнозов.
- **Адаптивное экспоненциальное сглаживание (AES)**: Использовалась динамическая настройка параметра сглаживания (α) с учётом изменений в данных.

![Описание изображения](./images/Unknown-25.png)
![Описание изображения](./images/Unknown-26.png)

### 1.5 Оценка качества моделей
- Для оценки качества прогнозов использовались метрики:
  - **MAE (Средняя абсолютная ошибка)**
  - **MSE (Среднеквадратичная ошибка)**
  - **MAPE (Средняя абсолютная процентная ошибка)**

### 1.6 Улучшение результатов
- Проведена оптимизация параметров α и γ для AES с использованием перебора по сетке параметров.
![Описание изображения](./images/Unknown-27.png)


## 2. Инструменты

- **Pandas**: Использовался для обработки данных, работы с временными рядами и ресемплирования.
- **Matplotlib и Seaborn**: Визуализация данных и результатов сглаживания.
- **Statsmodels**: Реализация простого экспоненциального сглаживания.
- **Numpy**: Математические операции для реализации адаптивного сглаживания.
- **Sklearn**: Метрики качества прогнозов.

## 3. Обоснование инструментов и метрик качества

- **Простое экспоненциальное сглаживание** подходит для данных, где отсутствует явный тренд или сезонность.
- **Адаптивное сглаживание** было использовано для учёта нестабильности данных, что улучшает гибкость модели.
- **MAE и MSE** оценивают точность прогноза в абсолютных и квадратичных значениях, что полезно для понимания масштабов ошибок.
- **MAPE** удобен для оценки ошибок в процентах, особенно для сравнения между тикерами.

## 4. Результаты и их интерпретация

### 4.1 Оценка методов сглаживания
- **SES**
  - Агрегированные метрики: MAE = 9.13, MSE = 292.31, MAPE = 19.69%.
  - Метод показал низкую устойчивость к резким изменениям в данных, что отразилось на высоких значениях ошибок.
- **AES**
  - Агрегированные метрики: MAE = 2.51, MSE = 25.26, MAPE = 5.22%.
  - Гибкость метода позволила значительно снизить ошибки, что делает его предпочтительным для данного набора данных.

### 4.2 Оптимизация параметров AES
- Подбор параметров (α, γ) позволил найти комбинации, минимизирующие MAE, что дополнительно улучшило точность модели.

### 4.3 Визуализация результатов
- Построены графики тренировочных и тестовых данных, прогнозов и сглаженных значений для каждого тикера. Графики наглядно показывают, что AES лучше адаптируется к изменениям временных рядов.

## 5. Общие выводы

- Использование адаптивного сглаживания показало себя как наиболее эффективный подход из уже осуществленных для прогнозирования временных рядов с высокой волатильностью.
- Применение сеточного поиска параметров улучшило метрики качества, подтвердив важность подбора оптимальных гиперпараметров.
- Ресемплирование данных и тщательная обработка выбросов и пропусков являются критически важными этапами для подготовки данных.

## 6. Рекомендации

- Для дальнейшего улучшения качества прогнозов возможно использование более сложных моделей, таких как ARIMA, SARIMAX или нейронные сети (LSTM, GRU).
- Необходимо учитывать сезонность и тренды, если такие зависимости будут выявлены в данных.
- Расширить оптимизацию за счёт увеличения диапазона параметров сетки.

# Часть 2 #
# Анализ и выводы по предварительной обработке данных для модели ARIMA
#### **Что было сделано:**

1. **Предварительная обработка данных:**

   - Загрузка данных из файла `daily_bars.csv`, содержащего ежедневные цены акций.

   - Преобразование формата даты и ресемплирование данных по неделям. В этом процессе использовались средние значения `adjusted_close` для каждой недели.Ресемплирование по неделям позволило сгладить колебания цен и выявить более устойчивые тренды, что облегчает анализ временных рядов и повышает точность прогнозирования.

   - Результаты были сохранены в словарь `weekly_data_dict`, где ключом является тикер, а значениями — недельные данные по ценам акций.

  



2. **Проверка данных на пропуски и выбросы:**

   - Анализ данных для выявления пропущенных значений и выбросов.

   - Линейная интерполяция применялась для устранения пропусков.

   - Для выявления выбросов использовался метод межквартильного размаха (IQR). Данные, выходящие за пределы 1.5 × IQR, считались выбросами, и их количество фиксировалось.

   - Результаты анализа (количество пропусков, выбросов и их процентное соотношение) были сохранены и выведены в сводной таблице.
  
Пропуски в данных успешно устранены с использованием интерполяции.
Большинство тикеров имели выбросы, но их процентное соотношение в общем объёме данных было невелико (менее 5%), что указывает на хорошее качество данных.




3. **Моделирование и прогнозирование с помощью ARIMA:**

   - Для каждого тикера обучались модели ARIMA на основе исторических данных, разделённых на тренировочный и тестовый наборы.

   - Использование модели для генерации прогнозов на основе тестовых данных.

   - Прогнозы приводились к оригинальным значениям цен акций с использованием функции `reconstruct_prices`, которая реконструировала абсолютные значения из дифференцированных временных рядов.
 
 Модели ARIMA показали себя как эффективный инструмент для прогнозирования временных рядов:
 Прогнозы достаточно близко соответствовали реальным значениям.
 Однако на отдельных участках наблюдались расхождения, особенно в периодах высокой волатильности, что свидетельствует о чувствительности ARIMA к резким изменениям. Прогнозы, полученные с помощью ARIMA, могут быть использованы для оценки будущих цен акций и построения стратегий торговли. Однако для повышения точности можно рассмотреть комбинирование ARIMA с другими моделями, такими как LSTM или Prophet.


4. **Визуализация прогнозов:**

   - Для первых 10 тикеров построены графики, где сравнивались:

     - Реальные значения цен акций.

     - Прогнозные значения, полученные от модели ARIMA.

     - Доверительные интервалы прогнозов.



5. **Сохранение итоговых данных:**

   - Словарь `weekly_data_dict` был преобразован в единый DataFrame и сохранён в формате `weekly_data_dict.csv` с колонками `date`, `adjusted_close` и `ticker`.



---





   - 



---



#### **Рекомендации:**

1. **Улучшение качества данных:**

   - Провести анализ сезонности, чтобы выявить более сложные зависимости в данных, которые могут быть учтены в модели.

   - Увеличить объём данных для обучения моделей, если это возможно.



2. **Оптимизация модели:**

   - Подбор гиперпараметров ARIMA (p, d, q) с использованием автоматизированных методов, таких как `auto_arima`.

   - Добавить модели GARCH или EGARCH для обработки волатильности.



3. **Альтернативные подходы:**

   - Использовать ансамбли моделей (например, комбинацию ARIMA с нейронными сетями).

   - Включить в анализ дополнительные факторы, такие как макроэкономические показатели или индикаторы настроений (sentiment analysis).



4. **Интеграция результатов:**

   - Использовать сохранённые данные из `weekly_data_dict.csv` для построения более сложных моделей и для дальнейшего анализа. 



Этот подход обеспечивает системный анализ данных, выявление основных закономерностей и позволяет строить более точные прогнозы.



## 1. Этапы анализа

### 1.1 Предварительная обработка данных
- **Описание данных**: Загрузка и первичная очистка данных, включая проверку на наличие пропусков и их устранение. Пропуски в столбце `adjusted_close` заменены медианными значениями для каждого тикера.

- **Ресемплирование данных**: Данные были приведены к недельной частоте, что упрощает анализ временных рядов и устраняет шумовые колебания на ежедневной основе.

![image](https://github.com/user-attachments/assets/33f2ca12-06a5-4858-9d1b-1519084acb73)

- **Удаление трендов**: Выполнено дифференцирование временных рядов для устранения трендовой составляющей. После этого данные были проверены на стационарность с использованием тестов ADF и KPSS. Результаты показали, что после первого дифференцирования временные ряды стали стационарными, что указывает на их принадлежность к процессу интегрированного порядка 1 (I(1)).

![image](https://github.com/user-attachments/assets/e4123d0f-7cef-4488-86dd-4f30b16626c6)


### 1.2 Построение автокорреляционных функций
- **ACF (Autocorrelation Function)**: На графиках ACF дифференцированного ряда наблюдается значимая автокорреляция на небольшом числе лагов (1-2). Это свидетельствует о том, что ряд может быть описан сравнительно простой ARMA-моделью низкого порядка.

- **PACF (Partial Autocorrelation Function)**: Графики PACF подтвердили наличие значимых пиков на тех же лагах, что указывает на низкий порядок авторегрессии. Это позволяет предположить использование моделей ARIMA(1,1,0) или ARIMA(0,1,1) для описания исходного ряда.

![image](https://github.com/user-attachments/assets/d24eaf74-0a63-488f-bf5f-13ead0d20b83)

![image](https://github.com/user-attachments/assets/b0af7fe2-cfca-4b11-ad6b-e030b9f4eb72)

### 1.3 Разделение данных
- Данные были разделены на тренировочную и тестовую выборки в пропорции 80/20. Это обеспечивает возможность обучения модели на одной части данных и проверки её качества на другой.

### 1.5 Настройка параметров ARIMA
- На основе графиков ACF и PACF были определены начальные параметры \(p\), \(d\), \(q\) для модели ARIMA. Эти параметры будут уточнены в процессе тестирования и оптимизации модели.

## 2. Инструменты

- **Pandas**: Для обработки данных и выполнения преобразований.
- **Matplotlib и Seaborn**: Для построения графиков временных рядов и автокорреляционных функций.
- **Statsmodels**: Для выполнения тестов на стационарность (ADF, KPSS) и построения ACF и PACF.



## 3. Общие выводы

- Проведённая обработка данных подготовила их к дальнейшему моделированию с использованием ARIMA.
- Результаты ACF и PACF указали на возможность использования моделей низкого порядка, таких как ARIMA(1,1,0) или ARIMA(0,1,1), однако окончательный выбор параметров будет уточнён при тестировании.
- Дифференцировка и проверка стационарности показали, что данные соответствуют процессу интегрированного порядка 1 (I(1)).




